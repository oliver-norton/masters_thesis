{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08a69431-2674-4dbf-8849-6b98db7e4426",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12491f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas==1.5.3 (from -r requirements.txt (line 1))\n",
      "  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (1.26.2)\n",
      "Requirement already satisfied: arrow in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (1.3.0)\n",
      "Collecting joblib (from -r requirements.txt (line 4))\n",
      "  Obtaining dependency information for joblib from https://files.pythonhosted.org/packages/10/40/d551139c85db202f1f384ba8bcf96aca2f329440a844f924c8a0040b6d02/joblib-1.3.2-py3-none-any.whl.metadata\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting openpyxl (from -r requirements.txt (line 5))\n",
      "  Downloading openpyxl-3.1.2-py2.py3-none-any.whl (249 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.0/250.0 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting dask (from -r requirements.txt (line 6))\n",
      "  Obtaining dependency information for dask from https://files.pythonhosted.org/packages/91/03/d3202129672be2931b3dad7407b24e98c0b847f7b158ffdf88d34cdcbbca/dask-2023.12.0-py3-none-any.whl.metadata\n",
      "  Downloading dask-2023.12.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas==1.5.3->-r requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas==1.5.3->-r requirements.txt (line 1)) (2023.3.post1)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /opt/conda/lib/python3.10/site-packages (from arrow->-r requirements.txt (line 3)) (2.8.19.14)\n",
      "Collecting et-xmlfile (from openpyxl->-r requirements.txt (line 5))\n",
      "  Downloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Requirement already satisfied: click>=8.1 in /opt/conda/lib/python3.10/site-packages (from dask->-r requirements.txt (line 6)) (8.1.7)\n",
      "Collecting cloudpickle>=1.5.0 (from dask->-r requirements.txt (line 6))\n",
      "  Obtaining dependency information for cloudpickle>=1.5.0 from https://files.pythonhosted.org/packages/96/43/dae06432d0c4b1dc9e9149ad37b4ca8384cf6eb7700cd9215b177b914f0a/cloudpickle-3.0.0-py3-none-any.whl.metadata\n",
      "  Downloading cloudpickle-3.0.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting fsspec>=2021.09.0 (from dask->-r requirements.txt (line 6))\n",
      "  Obtaining dependency information for fsspec>=2021.09.0 from https://files.pythonhosted.org/packages/96/0e/2be9b5a2e3f736577e749bbdf27a1e7e965041e1c908d49dedf56eeb2b8a/fsspec-2023.12.1-py3-none-any.whl.metadata\n",
      "  Downloading fsspec-2023.12.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from dask->-r requirements.txt (line 6)) (23.1)\n",
      "Collecting partd>=1.2.0 (from dask->-r requirements.txt (line 6))\n",
      "  Obtaining dependency information for partd>=1.2.0 from https://files.pythonhosted.org/packages/11/8a/b7a58e208b144a7315208a0dd627e23f5f50b47fa89c2924bb2e9238ecfb/partd-1.4.1-py3-none-any.whl.metadata\n",
      "  Downloading partd-1.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from dask->-r requirements.txt (line 6)) (6.0.1)\n",
      "Requirement already satisfied: toolz>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from dask->-r requirements.txt (line 6)) (0.12.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.13.0 in /opt/conda/lib/python3.10/site-packages (from dask->-r requirements.txt (line 6)) (6.8.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata>=4.13.0->dask->-r requirements.txt (line 6)) (3.17.0)\n",
      "Collecting locket (from partd>=1.2.0->dask->-r requirements.txt (line 6))\n",
      "  Downloading locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas==1.5.3->-r requirements.txt (line 1)) (1.16.0)\n",
      "Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.2/302.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading dask-2023.12.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading cloudpickle-3.0.0-py3-none-any.whl (20 kB)\n",
      "Downloading fsspec-2023.12.1-py3-none-any.whl (168 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.9/168.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading partd-1.4.1-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: locket, joblib, fsspec, et-xmlfile, cloudpickle, partd, pandas, openpyxl, dask\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.1.3\n",
      "    Uninstalling pandas-2.1.3:\n",
      "      Successfully uninstalled pandas-2.1.3\n",
      "Successfully installed cloudpickle-3.0.0 dask-2023.12.0 et-xmlfile-1.1.0 fsspec-2023.12.1 joblib-1.3.2 locket-1.0.0 openpyxl-3.1.2 pandas-1.5.3 partd-1.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "416d6bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import arrow\n",
    "import joblib\n",
    "import openpyxl\n",
    "import pickle\n",
    "import os\n",
    "from datetime import datetime, date, time, timedelta\n",
    "import random\n",
    "import copy\n",
    "import time \n",
    "import csv\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb9832c-3114-4626-90ee-23c666decc2f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# main pre-processing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8c5fd6-f04c-4e9e-8635-671a3669c24b",
   "metadata": {},
   "source": [
    "looping through and shrinking pkl files and storing in another directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66d280e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D25\n",
      "./Data/D25/election_v2_2022_APR_D25_21_02d_20231021.pkl\n",
      "election_v2_2022_APR_D25_21_02d_20231021.pkl\n",
      "./Data/D25/election_v2_2022_APR_D25_19_02d_20231021.pkl\n",
      "election_v2_2022_APR_D25_19_02d_20231021.pkl\n",
      "./Data/D25/election_v2_2022_APR_D25_22_02d_20231021.pkl\n",
      "election_v2_2022_APR_D25_22_02d_20231021.pkl\n",
      "./Data/D25/election_v2_2022_APR_D25_01_01_20231020.pkl\n",
      "election_v2_2022_APR_D25_01_01_20231020.pkl\n",
      "./Data/D25/election_v2_2022_APR_D25_08_08_20231020.pkl\n",
      "election_v2_2022_APR_D25_08_08_20231020.pkl\n",
      "./Data/D25/election_v2_2022_APR_D25_07_07_20231020.pkl\n",
      "election_v2_2022_APR_D25_07_07_20231020.pkl\n",
      "./Data/D25/election_v2_2022_APR_D25_09_09_20231020.pkl\n",
      "election_v2_2022_APR_D25_09_09_20231020.pkl\n",
      "./Data/D25/election_v2_2022_APR_D25_12_02d_20231020.pkl\n",
      "election_v2_2022_APR_D25_12_02d_20231020.pkl\n",
      "./Data/D25/election_v2_2022_APR_D25_13_02d_20231020.pkl\n",
      "election_v2_2022_APR_D25_13_02d_20231020.pkl\n",
      "./Data/D25/election_v2_2022_APR_D25_05_05_20231020.pkl\n",
      "election_v2_2022_APR_D25_05_05_20231020.pkl\n",
      "./Data/D25/election_v2_2022_APR_D25_06_06_20231020.pkl\n",
      "election_v2_2022_APR_D25_06_06_20231020.pkl\n",
      "./Data/D25/election_v2_2022_APR_D25_17_02d_20231020.pkl\n",
      "election_v2_2022_APR_D25_17_02d_20231020.pkl\n",
      "./Data/D25/election_v2_2022_APR_D25_00_00_20231020.pkl\n",
      "election_v2_2022_APR_D25_00_00_20231020.pkl\n",
      "./Data/D25/election_v2_2022_APR_D25_20_02d_20231021.pkl\n",
      "election_v2_2022_APR_D25_20_02d_20231021.pkl\n",
      "./Data/D25/election_v2_2022_APR_D25_18_02d_20231020.pkl\n",
      "election_v2_2022_APR_D25_18_02d_20231020.pkl\n",
      "./Data/D25/election_v2_2022_APR_D25_03_03_20231020.pkl\n",
      "election_v2_2022_APR_D25_03_03_20231020.pkl\n",
      "./Data/D25/election_v2_2022_APR_D25_14_02d_20231020.pkl\n",
      "election_v2_2022_APR_D25_14_02d_20231020.pkl\n",
      "./Data/D25/election_v2_2022_APR_D25_23_02d_20231021.pkl\n",
      "election_v2_2022_APR_D25_23_02d_20231021.pkl\n",
      "./Data/D25/election_v2_2022_APR_D25_04_04_20231020.pkl\n",
      "election_v2_2022_APR_D25_04_04_20231020.pkl\n",
      "./Data/D25/election_v2_2022_APR_D25_11_02d_20231020.pkl\n",
      "election_v2_2022_APR_D25_11_02d_20231020.pkl\n",
      "./Data/D25/election_v2_2022_APR_D25_10_02d_20231020.pkl\n",
      "election_v2_2022_APR_D25_10_02d_20231020.pkl\n",
      "./Data/D25/election_v2_2022_APR_D25_02_02_20231020.pkl\n",
      "election_v2_2022_APR_D25_02_02_20231020.pkl\n",
      "./Data/D25/election_v2_2022_APR_D25_15_02d_20231020.pkl\n",
      "election_v2_2022_APR_D25_15_02d_20231020.pkl\n",
      "./Data/D25/election_v2_2022_APR_D25_16_02d_20231020.pkl\n",
      "election_v2_2022_APR_D25_16_02d_20231020.pkl\n"
     ]
    }
   ],
   "source": [
    "# Directory where the data is located\n",
    "data_directory = './Data/'\n",
    "\n",
    "# Iterate through subfolders D02 to D25\n",
    "for subfolder in range(25, 26):\n",
    "    subfolder_name = f'D{subfolder:02d}'\n",
    "    print(subfolder_name)\n",
    "    subfolder_path = os.path.join(data_directory, subfolder_name)\n",
    "    \n",
    "    # Check if the subfolder exists\n",
    "    if os.path.exists(subfolder_path):\n",
    "        # Iterate through files in the subfolder\n",
    "\n",
    "        dfs = []\n",
    "\n",
    "        for file_name in os.listdir(subfolder_path):\n",
    "            file_path = os.path.join(subfolder_path, file_name)\n",
    "            print(file_path)\n",
    "            \n",
    "            # Check if the file is a pickle file\n",
    "            if file_name.endswith('.pkl'):\n",
    "                print(file_name)\n",
    "                # Load the pickle file and append it to the list of dataframes\n",
    "                try:\n",
    "                    with open(file_path, 'rb') as file:\n",
    "                        data = pickle.load(file)\n",
    "                        dfs.append(data)\n",
    "                except EOFError:\n",
    "                    print(\"EOFError: Failed to load data from the file.\")\n",
    "                except Exception as e:\n",
    "                    print(\"An error occurred:\", e)\n",
    "        \n",
    "        # Concatenate all dataframes into a single dataframe\n",
    "        df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "        df['date'] = pd.to_datetime(df['date'], infer_datetime_format=True)\n",
    "        df['day'] = df['date'].dt.date\n",
    "\n",
    "        # create source of retweet action\n",
    "        df['source'] = df['user'].apply(lambda x: x['screenName'] if x is not None and 'screenName' in x else None)\n",
    "\n",
    "        # Get target\n",
    "        df['target'] = df['retweet'].apply(lambda x: x['user']['screenName'] if (x and 'user' in x and 'screenName' in x['user']) else None)\n",
    "\n",
    "        df['weight'] = 1\n",
    "\n",
    "        # removing None - where there is just a tweet and no retweet\n",
    "        df = df.dropna(subset=['target'])\n",
    "\n",
    "        df_less_cols = df.copy()\n",
    "\n",
    "        df_less_cols = df_less_cols[['date','source','target','weight','day']]\n",
    "\n",
    "        output_directory = './data_pr_rt_2/'\n",
    "        os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "        # Assuming df_less_cols is your DataFrame\n",
    "        df_less_cols.to_pickle(os.path.join(output_directory, f'D{subfolder:02d}.pkl'))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51399d7-7ff5-45fe-9971-e3436f7a69ad",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#  preprocessing (repaired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "986f6054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D19\n",
      "D20\n",
      "./data_pr_rt_recollected/Recollected/D20/election_v2_2022_APR_D20_02_02_20231020.pkl\n",
      "election_v2_2022_APR_D20_02_02_20231020.pkl\n",
      "./data_pr_rt_recollected/Recollected/D20/election_v2_2022_APR_D20_19_02d_20231025.pkl\n",
      "election_v2_2022_APR_D20_19_02d_20231025.pkl\n",
      "./data_pr_rt_recollected/Recollected/D20/election_v2_2022_APR_D20_08_08_20231020.pkl\n",
      "election_v2_2022_APR_D20_08_08_20231020.pkl\n",
      "./data_pr_rt_recollected/Recollected/D20/election_v2_2022_APR_D20_11_02d_20231020.pkl\n",
      "election_v2_2022_APR_D20_11_02d_20231020.pkl\n",
      "./data_pr_rt_recollected/Recollected/D20/election_v2_2022_APR_D20_21_02d_20231025.pkl\n",
      "election_v2_2022_APR_D20_21_02d_20231025.pkl\n",
      "./data_pr_rt_recollected/Recollected/D20/election_v2_2022_APR_D20_18_02d_20231020.pkl\n",
      "election_v2_2022_APR_D20_18_02d_20231020.pkl\n",
      "./data_pr_rt_recollected/Recollected/D20/election_v2_2022_APR_D20_06_06_20231020.pkl\n",
      "election_v2_2022_APR_D20_06_06_20231020.pkl\n",
      "./data_pr_rt_recollected/Recollected/D20/election_v2_2022_APR_D20_03_03_20231020.pkl\n",
      "election_v2_2022_APR_D20_03_03_20231020.pkl\n",
      "./data_pr_rt_recollected/Recollected/D20/election_v2_2022_APR_D20_01_01_20231020.pkl\n",
      "election_v2_2022_APR_D20_01_01_20231020.pkl\n",
      "./data_pr_rt_recollected/Recollected/D20/election_v2_2022_APR_D20_13_02d_20231020.pkl\n",
      "election_v2_2022_APR_D20_13_02d_20231020.pkl\n",
      "./data_pr_rt_recollected/Recollected/D20/election_v2_2022_APR_D20_15_02d_20231020.pkl\n",
      "election_v2_2022_APR_D20_15_02d_20231020.pkl\n",
      "./data_pr_rt_recollected/Recollected/D20/election_v2_2022_APR_D20_20_02d_20231025.pkl\n",
      "election_v2_2022_APR_D20_20_02d_20231025.pkl\n",
      "./data_pr_rt_recollected/Recollected/D20/election_v2_2022_APR_D20_14_02d_20231020.pkl\n",
      "election_v2_2022_APR_D20_14_02d_20231020.pkl\n",
      "./data_pr_rt_recollected/Recollected/D20/election_v2_2022_APR_D20_12_02d_20231020.pkl\n",
      "election_v2_2022_APR_D20_12_02d_20231020.pkl\n",
      "./data_pr_rt_recollected/Recollected/D20/election_v2_2022_APR_D20_04_04_20231020.pkl\n",
      "election_v2_2022_APR_D20_04_04_20231020.pkl\n",
      "./data_pr_rt_recollected/Recollected/D20/election_v2_2022_APR_D20_16_02d_20231020.pkl\n",
      "election_v2_2022_APR_D20_16_02d_20231020.pkl\n",
      "./data_pr_rt_recollected/Recollected/D20/election_v2_2022_APR_D20_17_02d_20231020.pkl\n",
      "election_v2_2022_APR_D20_17_02d_20231020.pkl\n",
      "./data_pr_rt_recollected/Recollected/D20/election_v2_2022_APR_D20_07_07_20231020.pkl\n",
      "election_v2_2022_APR_D20_07_07_20231020.pkl\n",
      "./data_pr_rt_recollected/Recollected/D20/election_v2_2022_APR_D20_05_05_20231020.pkl\n",
      "election_v2_2022_APR_D20_05_05_20231020.pkl\n",
      "./data_pr_rt_recollected/Recollected/D20/election_v2_2022_APR_D20_09_09_20231020.pkl\n",
      "election_v2_2022_APR_D20_09_09_20231020.pkl\n",
      "./data_pr_rt_recollected/Recollected/D20/election_v2_2022_APR_D20_00_00_20231020.pkl\n",
      "election_v2_2022_APR_D20_00_00_20231020.pkl\n",
      "./data_pr_rt_recollected/Recollected/D20/election_v2_2022_APR_D20_10_02d_20231020.pkl\n",
      "election_v2_2022_APR_D20_10_02d_20231020.pkl\n",
      "./data_pr_rt_recollected/Recollected/D20/election_v2_2022_APR_D20_22_02d_20231023.pkl\n",
      "election_v2_2022_APR_D20_22_02d_20231023.pkl\n",
      "./data_pr_rt_recollected/Recollected/D20/election_v2_2022_APR_D20_23_02d_20231023.pkl\n",
      "election_v2_2022_APR_D20_23_02d_20231023.pkl\n"
     ]
    }
   ],
   "source": [
    "# Directory where the data is located\n",
    "data_directory = './data_pr_rt_recollected/Recollected/'\n",
    "\n",
    "\n",
    "# Iterate through subfolders D02 to D25\n",
    "for subfolder in range(19, 21):\n",
    "    subfolder_name = f'D{subfolder:02d}'\n",
    "    print(subfolder_name)\n",
    "    subfolder_path = os.path.join(data_directory, subfolder_name)\n",
    "    \n",
    "    # Check if the subfolder exists\n",
    "    if os.path.exists(subfolder_path):\n",
    "        # Iterate through files in the subfolder\n",
    "\n",
    "        dfs = []\n",
    "\n",
    "        for file_name in os.listdir(subfolder_path):\n",
    "            file_path = os.path.join(subfolder_path, file_name)\n",
    "            print(file_path)\n",
    "            \n",
    "            # Check if the file is a pickle file\n",
    "            if file_name.endswith('.pkl'):\n",
    "                print(file_name)\n",
    "                # Load the pickle file and append it to the list of dataframes\n",
    "                try:\n",
    "                    with open(file_path, 'rb') as file:\n",
    "                        data = pickle.load(file)\n",
    "                        dfs.append(data)\n",
    "                except EOFError:\n",
    "                    print(\"EOFError: Failed to load data from the file.\")\n",
    "                except Exception as e:\n",
    "                    print(\"An error occurred:\", e)\n",
    "        \n",
    "        # Concatenate all dataframes into a single dataframe\n",
    "        df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "        df['date'] = pd.to_datetime(df['date'], infer_datetime_format=True)\n",
    "        df['day'] = df['date'].dt.date\n",
    "\n",
    "        # create source of retweet action\n",
    "        df['source'] = df['user'].apply(lambda x: x['screenName'] if x is not None and 'screenName' in x else None)\n",
    "\n",
    "        # Get target\n",
    "        df['target'] = df['retweet'].apply(lambda x: x['user']['screenName'] if (x and 'user' in x and 'screenName' in x['user']) else None)\n",
    "\n",
    "        df['weight'] = 1\n",
    "\n",
    "        df = df.copy()\n",
    "\n",
    "        # df = df.drop_duplicates()\n",
    "\n",
    "        # removing None - where there is just a tweet and no retweet\n",
    "        df = df.dropna(subset=['target'])\n",
    "\n",
    "        df_less_cols = df.copy()\n",
    "\n",
    "        df_less_cols = df_less_cols[['date','source','target','weight','day']]\n",
    "\n",
    "        output_directory = './data_pr_rt/'\n",
    "        os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "        # Assuming df_less_cols is your DataFrame\n",
    "        df_less_cols.to_pickle(os.path.join(output_directory, f'D{subfolder:02d}.pkl'))\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1ea37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index(['affects', 'category', 'contentClassification', 'date', 'emotion',\n",
    "#        'engagementScore', 'externalUrl', 'focuses', 'geo', 'hashtag',\n",
    "#        'highlights', 'id', 'idStr', 'impression', 'inReplyToStatusId',\n",
    "#        'inReplyToStatusIdStr', 'isQuote', 'isRT', 'keyphrase', 'keyword',\n",
    "#        'lang', 'media', 'mentions', 'origin', 'permaSlink', 'quote', 'radar',\n",
    "#        'reach', 'retweet', 'score', 'story', 'text', 'tone', 'uid', 'user',\n",
    "#        'month', 'year'],\n",
    "#       dtype='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626f6fae",
   "metadata": {},
   "source": [
    "# Importing processed tweets "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a94041b-d8b0-4065-8828-52c3a99b523f",
   "metadata": {},
   "source": [
    "concats all the pkl files by day into large file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a27d301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D14.pkl\n",
      "D06.pkl\n",
      "D09.pkl\n",
      "D07.pkl\n",
      "D13.pkl\n",
      "D02.pkl\n",
      "D17.pkl\n",
      "D11.pkl\n",
      "D20.pkl\n",
      "D05.pkl\n",
      "D23.pkl\n",
      "D25.pkl\n",
      "D03.pkl\n",
      "D08.pkl\n",
      "D19.pkl\n",
      "D18.pkl\n",
      "D24.pkl\n",
      "D22.pkl\n",
      "D21.pkl\n",
      "D15.pkl\n",
      "D04.pkl\n",
      "D16.pkl\n",
      "D10.pkl\n",
      "D01.pkl\n",
      "                       date       source          target  weight         day\n",
      "0 2022-04-14 05:00:00+00:00     ARNHED71        CBarrely       1  2022-04-14\n",
      "1 2022-04-14 05:00:00+00:00  DoubleVPenn   2022Elections       1  2022-04-14\n",
      "2 2022-04-14 05:00:00+00:00    Titians20    BOROWSKIMIKE       1  2022-04-14\n",
      "3 2022-04-14 05:00:00+00:00   jcmartin87  HamsterFreedom       1  2022-04-14\n",
      "4 2022-04-14 05:00:00+00:00     bert6691  LaurianeTroise       1  2022-04-14\n"
     ]
    }
   ],
   "source": [
    "folder_path = './data_pr_rt_2/'\n",
    "file_list = [file for file in os.listdir(folder_path) if file.endswith('.pkl')]\n",
    "dfs = []\n",
    "\n",
    "for file in file_list:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    # Assuming the data is stored as a DataFrame in each .pkl file\n",
    "    df = pd.read_pickle(file_path)\n",
    "    dfs.append(df)\n",
    "    print(file)\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Now, concatenated_df contains the data from all .pkl files in the folder\n",
    "print(df.head())  # Print the first few rows of the concatenated DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bfe44ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>weight</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-04-14 05:00:00+00:00</td>\n",
       "      <td>ARNHED71</td>\n",
       "      <td>CBarrely</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-04-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-04-14 05:00:00+00:00</td>\n",
       "      <td>DoubleVPenn</td>\n",
       "      <td>2022Elections</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-04-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-04-14 05:00:00+00:00</td>\n",
       "      <td>Titians20</td>\n",
       "      <td>BOROWSKIMIKE</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-04-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-04-14 05:00:00+00:00</td>\n",
       "      <td>jcmartin87</td>\n",
       "      <td>HamsterFreedom</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-04-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-04-14 05:00:00+00:00</td>\n",
       "      <td>bert6691</td>\n",
       "      <td>LaurianeTroise</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-04-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date       source          target  weight         day\n",
       "0 2022-04-14 05:00:00+00:00     ARNHED71        CBarrely       1  2022-04-14\n",
       "1 2022-04-14 05:00:00+00:00  DoubleVPenn   2022Elections       1  2022-04-14\n",
       "2 2022-04-14 05:00:00+00:00    Titians20    BOROWSKIMIKE       1  2022-04-14\n",
       "3 2022-04-14 05:00:00+00:00   jcmartin87  HamsterFreedom       1  2022-04-14\n",
       "4 2022-04-14 05:00:00+00:00     bert6691  LaurianeTroise       1  2022-04-14"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53d96ffe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160966"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.target.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d6f209c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16089093"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "213db7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before removing duplicates: 16089093\n",
      "Number of rows after removing duplicates: 16073433\n",
      "Number of duplicates removed: 15660\n"
     ]
    }
   ],
   "source": [
    "# Print the number of rows before removing duplicates\n",
    "print(\"Number of rows before removing duplicates:\", len(df))\n",
    "\n",
    "# Remove duplicates\n",
    "df_no_dup = df.drop_duplicates()\n",
    "\n",
    "# Print the number of rows after removing duplicates\n",
    "print(\"Number of rows after removing duplicates:\", len(df_no_dup))\n",
    "\n",
    "# Print the number of duplicates removed\n",
    "duplicates_removed = len(df) - len(df_no_dup)\n",
    "print(\"Number of duplicates removed:\", duplicates_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d398d2fb-3443-42d4-a0fd-d84ac5e0b45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to rt_net to csv  \n",
    "current_directory = os.getcwd()\n",
    "parent_directory = os.path.dirname(current_directory)\n",
    "\n",
    "# unfiltered dataset (date,source,target,weight,day)\n",
    "excel_file_path = os.path.join(parent_directory, 'data', 'load', 'rt_net_unfiltered_2023-12-11_dup.csv')\n",
    "df.to_csv(excel_file_path, index=False,header=False)\n",
    "\n",
    "# filtered (source,target,weight)\n",
    "df_filtered_2 = df[['source','target','weight']]\n",
    "excel_file_path = os.path.join(parent_directory, 'data', 'load', 'rt_net_filtered_2023-12-11_dup.csv')\n",
    "df_filtered_2.to_csv(excel_file_path, index=False,header=False)\n",
    "\n",
    "# filtered and summed \n",
    "df_filtered_3 = df.groupby(['source', 'target'])['weight'].sum().reset_index()\n",
    "excel_file_path = os.path.join(parent_directory, 'data', 'load', 'rt_net_filtered_weighted_2023-12-11_dup.csv')\n",
    "df_filtered_3.to_csv(excel_file_path, index=False,header=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6421ca7-638c-4d84-9fd1-7cd7072a05de",
   "metadata": {},
   "source": [
    "### Load opinion leaders list (gross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0a7a5b5-e1e6-4bb8-9dbb-98a62f303336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Duplicate?</th>\n",
       "      <th>Handle</th>\n",
       "      <th>Twitter URL</th>\n",
       "      <th>Position</th>\n",
       "      <th>Affilation</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>PapNdiaye</td>\n",
       "      <td>https://twitter.com/PapNdiaye</td>\n",
       "      <td>Government</td>\n",
       "      <td>LREM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>sretailleau</td>\n",
       "      <td>https://twitter.com/sretailleau</td>\n",
       "      <td>Government</td>\n",
       "      <td>LREM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>RimaAbdulMalak</td>\n",
       "      <td>https://twitter.com/RimaAbdulMalak</td>\n",
       "      <td>Government</td>\n",
       "      <td>LREM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>E_DupondM</td>\n",
       "      <td>https://twitter.com/E_DupondM</td>\n",
       "      <td>Government</td>\n",
       "      <td>LREM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>MinColonna</td>\n",
       "      <td>https://twitter.com/MinColonna</td>\n",
       "      <td>Government</td>\n",
       "      <td>LREM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Duplicate?          Handle                         Twitter URL    Position  \\\n",
       "0       False       PapNdiaye       https://twitter.com/PapNdiaye  Government   \n",
       "1       False     sretailleau     https://twitter.com/sretailleau  Government   \n",
       "2       False  RimaAbdulMalak  https://twitter.com/RimaAbdulMalak  Government   \n",
       "3       False       E_DupondM       https://twitter.com/E_DupondM  Government   \n",
       "4       False      MinColonna      https://twitter.com/MinColonna  Government   \n",
       "\n",
       "  Affilation Comment  \n",
       "0       LREM     NaN  \n",
       "1       LREM     NaN  \n",
       "2       LREM     NaN  \n",
       "3       LREM     NaN  \n",
       "4       LREM     NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the 'all_mps' sheet from the Excel file\n",
    "df_elites = pd.read_excel('./input/Elite actors.xlsx', sheet_name='all_mps')\n",
    "df_elites.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6bb2b8c-d2b2-4704-9c2b-379f50fb7569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LREM    294\n",
       "RN      105\n",
       "LR       98\n",
       "LFI      73\n",
       "EELV     17\n",
       "RQ       11\n",
       "Name: Affilation, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_elites.Affilation.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d584fff1-f09d-487f-abf6-c7580fca6d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "598"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_elites.Affilation.value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae0c87e-d537-41cd-af22-94b78f3ffc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the 'all_mps' sheet from the Excel file\n",
    "df_constituencies = pd.read_excel('./input/Elite actors.xlsx', sheet_name='constituency_results')\n",
    "df_constituencies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c16c6fe-ed2f-445b-a261-684003d098db",
   "metadata": {},
   "source": [
    "### How many elites are present in our initial dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a597d8a1-5e11-446a-aa8c-61519cc617a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handles found in the target list: 408\n",
      "Handles not found in the target list: 190\n"
     ]
    }
   ],
   "source": [
    "# Extract the 'twitter_handle' values from df_elites and filtered_targets\n",
    "twitter_handles_in_df = df_elites['Handle']\n",
    "twitter_handles_in_target = df['target']\n",
    "\n",
    "# Find twitter handles that are in the target list\n",
    "handles_found_in_target = twitter_handles_in_df[twitter_handles_in_df.isin(twitter_handles_in_target)].tolist()\n",
    "\n",
    "# Find twitter handles that are not in the target list\n",
    "handles_not_found_in_target = twitter_handles_in_df[~twitter_handles_in_df.isin(twitter_handles_in_target)].tolist()\n",
    "\n",
    "print(\"Handles found in the target list:\", len(handles_found_in_target))\n",
    "print(\"Handles not found in the target list:\", len(handles_not_found_in_target))\n",
    "# print(*handles_found_in_target, sep=' ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdd0391-2234-41a3-9b0c-f5020a2b15c9",
   "metadata": {},
   "source": [
    "# filter by influence "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57558077-7820-4248-9f69-132f5b7a28cb",
   "metadata": {},
   "source": [
    "min 1000 retweets - this is used to find out how many opinion leaders are left in there, but the final dataset won't remove these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ac8572f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### filter by influence (1000 rt)\n",
    "df_influential_users = df.copy()\n",
    "\n",
    "df_influential_users = df_influential_users[df_influential_users.groupby('target')['weight'].transform('sum') > 400]\n",
    "df_influential_users = df_influential_users.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0e335263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 2956610 less tweets after filtering out non-influential users <500 retweets\n"
     ]
    }
   ],
   "source": [
    "print('there are ' + str(len(df) - len(df_influential_users)) + ' less tweets after filtering out non-influential users <500 retweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "546e5a43-8d16-4d19-bbb0-e782fe8eed72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 166961 less elites after filtering out non-influential users <1000 retweets, and now a total of 4696 unique users left, from 171657\n"
     ]
    }
   ],
   "source": [
    "print('there are ' + str(len(df.target.unique()) - len(df_influential_users.target.unique())) + ' less elites after filtering out non-influential users <1000 retweets, and now a total of ' + str(len(df_influential_users.target.unique())) + ' unique users left, from ' + str(len(df.target.unique()))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ed696856-24a5-4e2c-8aa8-04c840d9397d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Politicians who are influential: 128\n",
      "Politicians who are not influential: 470\n"
     ]
    }
   ],
   "source": [
    "# find out how many MPs are influential \n",
    "\n",
    "# Extract the 'twitter_handle' values from df_elites and filtered_targets\n",
    "twitter_handles_in_df = df_elites['Handle']\n",
    "twitter_handles_in_target = df_influential_users['target']\n",
    "\n",
    "# Find twitter handles that are in the target list\n",
    "handles_found_in_target = twitter_handles_in_df[twitter_handles_in_df.isin(twitter_handles_in_target)].tolist()\n",
    "\n",
    "# Find twitter handles that are not in the target list\n",
    "handles_not_found_in_target = twitter_handles_in_df[~twitter_handles_in_df.isin(twitter_handles_in_target)].tolist()\n",
    "\n",
    "print(\"Politicians who are influential:\", len(handles_found_in_target))\n",
    "print(\"Politicians who are not influential:\", len(handles_not_found_in_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3f2a0d4f-a637-4944-8a64-53a18da690c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LREM    54\n",
       "LFI     27\n",
       "RN      25\n",
       "LR      11\n",
       "RQ       7\n",
       "EELV     4\n",
       "Name: Affilation, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_elites[df_elites['Handle'].isin(handles_found_in_target)]['Affilation'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53f4083",
   "metadata": {},
   "source": [
    "# filter by participation rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdad3f12-8472-49dd-a0cf-f62edaa81b9c",
   "metadata": {},
   "source": [
    "still looking for opinion leaders who are left in after participation rate reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "76111fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### filter by participation rate\n",
    "# Group by 'day' and 'target' and count the occurrences\n",
    "target_counts_per_day = df_influential_users.groupby(['day', 'target']).size().reset_index(name='count')\n",
    "# Get the total number of unique days in the dataset\n",
    "# total_days = df_influential_users['day'].nunique()\n",
    "\n",
    "total_days = 17 # 70% participation rate \n",
    "# Filter targets that appear at least once every day\n",
    "filtered_targets = target_counts_per_day.groupby('target').filter(lambda x: len(x) >= total_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6ecabbaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>target</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>100drine_Juste</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>13WolfLee</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>17_so2020</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>1968Framboisine</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>1ElisaMoreno</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          day           target  count\n",
       "0  2022-04-01   100drine_Juste      3\n",
       "1  2022-04-01        13WolfLee      2\n",
       "2  2022-04-01        17_so2020      5\n",
       "3  2022-04-01  1968Framboisine      2\n",
       "4  2022-04-01     1ElisaMoreno     24"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_targets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f32a8f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61914"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1d48e9-ee62-4a84-a123-3313a5f3325e",
   "metadata": {},
   "source": [
    "### find opinion leaders from gross list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d13defba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handles found in the target list: 119\n",
      "Handles not found in the target list: 479\n",
      "CZacharopoulou AgnesRunacher ChristopheBechu al_petel Elisabeth_Borne franckriester CBeaune GabrielAttal alexiscorbiere SebLecornu olivierdussopt GDarmanin alma_dufour barbarapompili BrunoLeMaire FJolivet36 RolandLescure AdeMontchalin CoDubost OlgaGivernet AVFreschi LaetitiaAvia MarieLebec78 Sebastien_Nadot EmilieCChalas AChristine_Lang GillesLeGendre moreaujb23 BrigBourguignon Aurelientache ebothorel RichardFerrand trudigoz BQuestel SachaHoulie SylvainMaillard mguevenoux EliseFajgeles CCastaner jmzulesi saidahamada sarahelhairy auroreberge EmmanuelMacron avecvous MLP_officiel BlairyEmmanuel PhOlivierRN HeleneLaporteRN diaz_edwige M_Dauchy A_Masson06 DominiqueBilde v_joron JLechanteux ljacobelli BrunoBilde J_Bardella LaureLavalette BallardPhilippe NMeizonnet sebchenu JulienOdoul JphTanguy franckallisio YoannGillet30 jllacapelle JPGarraud ThierryMARIANI ZemmourEric MarionMarechal NicolasBay_ stanislasrig DamienRieu AntoineBaudino JLMelenchon jnbarrot BenedictTaurine PrudhommeLoic Deputee_Obono Michel_Larive Francois_Ruffin TrouveAurelie CaronAymericoff AQuatennens MarianneMaximi Portes_Thomas MathildePanot mbompard FraPiquemal Clem_Autain GuiraudInd Clemence_Guette ericcoquerel LachaudB WilliamMartinet RaquelGarridoFr Ugobernalicis ALeaument SergioCoronado CecileDuflot EELV yjadot vpecresse npouzyreff78 oliviagregoire olivierveran maudgatel StanGuerini sebastienjumel YaelBRAUNPIVET enmarchefr ECiotti phdumont oliviermarleix brigitte_kuster ChJacob77 JulienAubert84 GLarrive\n"
     ]
    }
   ],
   "source": [
    "# Extract the 'twitter_handle' values from df_elites and filtered_targets\n",
    "twitter_handles_in_df = df_elites['Handle']\n",
    "twitter_handles_in_target = filtered_targets['target']\n",
    "\n",
    "# Find twitter handles that are in the target list\n",
    "handles_found_in_target = twitter_handles_in_df[twitter_handles_in_df.isin(twitter_handles_in_target)].tolist()\n",
    "\n",
    "# Find twitter handles that are not in the target list\n",
    "handles_not_found_in_target = twitter_handles_in_df[~twitter_handles_in_df.isin(twitter_handles_in_target)].tolist()\n",
    "\n",
    "print(\"Handles found in the target list:\", len(handles_found_in_target))\n",
    "print(\"Handles not found in the target list:\", len(handles_not_found_in_target))\n",
    "print(*handles_found_in_target, sep=' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d524c770",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_elites_opinion_leaders_present = df_elites[df_elites['Handle'].isin(handles_found_in_target)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6216b712-cedc-4805-85ca-3ad3f5f3fe79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LREM    50\n",
       "LFI     25\n",
       "RN      24\n",
       "LR      10\n",
       "RQ       6\n",
       "EELV     4\n",
       "Name: Affilation, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_elites_opinion_leaders_present.Affilation.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "25ed0569-6cd3-476b-9b96-c02727ad4d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_198/2480142810.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_elites_opinion_leaders_present.rename(columns={'Affilation': 'Affiliation'}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df_elites_opinion_leaders_present.rename(columns={'Affilation': 'Affiliation'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "cc458f9c-4524-473b-8768-f5305688db26",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['Affiliation', 'Handle','Position']\n",
    "df_selected = df_elites_opinion_leaders_present[selected_columns].copy()\n",
    "\n",
    "# Rename affiliations as specified\n",
    "affiliation_mapping = {'LREM': 'Ens', 'LFI': 'NUPES', 'RN': 'RN', 'LR': 'LR', 'EELV': 'NUPES'}\n",
    "df_selected['Affiliation'] = df_selected['Affiliation'].map(affiliation_mapping)\n",
    "# Remove rows where affiliation is 'RQ'\n",
    "df_filtered = df_filtered[(df_filtered['Affiliation'] == 'Ens') | (df_filtered['Affiliation'] == 'RN') | (df_filtered['Affiliation'] == 'LR') | (df_filtered['Affiliation'] == 'NUPES')]\n",
    "\n",
    "df_filtered = df_filtered.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "62386258-9a1e-429b-9ca4-bc418447aa96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Affiliation</th>\n",
       "      <th>Handle</th>\n",
       "      <th>Position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ens</td>\n",
       "      <td>CZacharopoulou</td>\n",
       "      <td>Government</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ens</td>\n",
       "      <td>AgnesRunacher</td>\n",
       "      <td>Government</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ens</td>\n",
       "      <td>ChristopheBechu</td>\n",
       "      <td>Government</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ens</td>\n",
       "      <td>al_petel</td>\n",
       "      <td>MP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ens</td>\n",
       "      <td>Elisabeth_Borne</td>\n",
       "      <td>Government</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>LR</td>\n",
       "      <td>oliviermarleix</td>\n",
       "      <td>MP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>LR</td>\n",
       "      <td>brigitte_kuster</td>\n",
       "      <td>Ex-MP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>LR</td>\n",
       "      <td>ChJacob77</td>\n",
       "      <td>Ex-MP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>LR</td>\n",
       "      <td>JulienAubert84</td>\n",
       "      <td>Ex-MP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>LR</td>\n",
       "      <td>GLarrive</td>\n",
       "      <td>Ex-MP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Affiliation           Handle    Position\n",
       "0           Ens   CZacharopoulou  Government\n",
       "1           Ens    AgnesRunacher  Government\n",
       "2           Ens  ChristopheBechu  Government\n",
       "3           Ens         al_petel          MP\n",
       "4           Ens  Elisabeth_Borne  Government\n",
       "..          ...              ...         ...\n",
       "108          LR   oliviermarleix          MP\n",
       "109          LR  brigitte_kuster       Ex-MP\n",
       "110          LR        ChJacob77       Ex-MP\n",
       "111          LR   JulienAubert84       Ex-MP\n",
       "112          LR         GLarrive       Ex-MP\n",
       "\n",
       "[113 rows x 3 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e392c586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_elites_opinion_leaders_present[df_elites_opinion_leaders_present['Affilation']=='RN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5042dc6e-9c26-4b89-b658-4fc6f20e10d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "current_directory = os.getcwd()\n",
    "parent_directory = os.path.dirname(current_directory)\n",
    "excel_file_path = os.path.join(parent_directory, 'data', 'twitter_handles', 'opinion_leaders_113.xlsx')\n",
    "df_filtered.to_excel(excel_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "fcc679cc-e534-46c2-af82-cb4017079325",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = os.getcwd()\n",
    "parent_directory = os.path.dirname(current_directory)\n",
    "excel_file_path = os.path.join(parent_directory, 'data', 'twitter_handles', 'opinion_leaders_113.csv')\n",
    "df_filtered['Handle'].to_csv(excel_file_path, index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e9bb6afb-3246-4c56-bbc2-f29d410a72f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_filtered['Handle'].unique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
