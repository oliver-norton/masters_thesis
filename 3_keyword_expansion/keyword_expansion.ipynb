{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "263b84a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting scikit-learn (from -r requirements_short.txt (line 1))\n",
      "  Obtaining dependency information for scikit-learn from https://files.pythonhosted.org/packages/7d/af/03d3a7d5719d00486c296ddd876e6f07a681bc4e079cb45348d2f261a748/scikit_learn-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading scikit_learn-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting nltk (from -r requirements_short.txt (line 2))\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/ucloud/.local/lib/python3.10/site-packages (from -r requirements_short.txt (line 3)) (1.26.0)\n",
      "Collecting pandas==1.5.3 (from -r requirements_short.txt (line 4))\n",
      "  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting matplotlib (from -r requirements_short.txt (line 5))\n",
      "  Obtaining dependency information for matplotlib from https://files.pythonhosted.org/packages/b5/24/aaccf324ce862bb82277e8814d2aebbb2a2c160d04e95aa2b8c9dc3137a9/matplotlib-3.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading matplotlib-3.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ucloud/.local/lib/python3.10/site-packages (from pandas==1.5.3->-r requirements_short.txt (line 4)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ucloud/.local/lib/python3.10/site-packages (from pandas==1.5.3->-r requirements_short.txt (line 4)) (2023.3.post1)\n",
      "Collecting scipy>=1.5.0 (from scikit-learn->-r requirements_short.txt (line 1))\n",
      "  Obtaining dependency information for scipy>=1.5.0 from https://files.pythonhosted.org/packages/18/44/7e8d208eb59a8224fcc474415104f13be9b378be8da63f76dfde12ec2b44/scipy-1.11.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading scipy-1.11.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.1.1 (from scikit-learn->-r requirements_short.txt (line 1))\n",
      "  Obtaining dependency information for joblib>=1.1.1 from https://files.pythonhosted.org/packages/10/40/d551139c85db202f1f384ba8bcf96aca2f329440a844f924c8a0040b6d02/joblib-1.3.2-py3-none-any.whl.metadata\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn->-r requirements_short.txt (line 1))\n",
      "  Obtaining dependency information for threadpoolctl>=2.0.0 from https://files.pythonhosted.org/packages/81/12/fd4dea011af9d69e1cad05c75f3f7202cdcbeac9b712eea58ca779a72865/threadpoolctl-3.2.0-py3-none-any.whl.metadata\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from nltk->-r requirements_short.txt (line 2)) (8.0.3)\n",
      "Collecting regex>=2021.8.3 (from nltk->-r requirements_short.txt (line 2))\n",
      "  Obtaining dependency information for regex>=2021.8.3 from https://files.pythonhosted.org/packages/8f/3e/4b8b40eb3c80aeaf360f0361d956d129bb3d23b2a3ecbe3a04a8f3bdd6d3/regex-2023.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading regex-2023.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tqdm (from nltk->-r requirements_short.txt (line 2))\n",
      "  Obtaining dependency information for tqdm from https://files.pythonhosted.org/packages/00/e5/f12a80907d0884e6dff9c16d0c0114d81b8cd07dc3ae54c5e962cc83037e/tqdm-4.66.1-py3-none-any.whl.metadata\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting contourpy>=1.0.1 (from matplotlib->-r requirements_short.txt (line 5))\n",
      "  Obtaining dependency information for contourpy>=1.0.1 from https://files.pythonhosted.org/packages/f1/6b/e4b0f8708f22dd7c321f87eadbb98708975e115ac6582eb46d1f32197ce6/contourpy-1.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading contourpy-1.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.9 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->-r requirements_short.txt (line 5))\n",
      "  Obtaining dependency information for cycler>=0.10 from https://files.pythonhosted.org/packages/2b/b3/70c33027c4918c10ccf176014b38f8b91cb18ac018a78854543a4fc72609/cycler-0.12.0-py3-none-any.whl.metadata\n",
      "  Downloading cycler-0.12.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->-r requirements_short.txt (line 5))\n",
      "  Obtaining dependency information for fonttools>=4.22.0 from https://files.pythonhosted.org/packages/30/fd/821dc3ba5d179bd9b20bf9a9c2251132a8f1067818d19fcafc987727ddaa/fonttools-4.43.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading fonttools-4.43.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (151 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m151.9/151.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1 (from matplotlib->-r requirements_short.txt (line 5))\n",
      "  Obtaining dependency information for kiwisolver>=1.0.1 from https://files.pythonhosted.org/packages/6f/40/4ab1fdb57fced80ce5903f04ae1aed7c1d5939dda4fd0c0aa526c12fe28a/kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata\n",
      "  Downloading kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ucloud/.local/lib/python3.10/site-packages (from matplotlib->-r requirements_short.txt (line 5)) (23.1)\n",
      "Collecting pillow>=6.2.0 (from matplotlib->-r requirements_short.txt (line 5))\n",
      "  Obtaining dependency information for pillow>=6.2.0 from https://files.pythonhosted.org/packages/7a/07/e896b096a77375e78e02ce222ae4fd6014928cd76c691d312060a1645dfa/Pillow-10.0.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata\n",
      "  Downloading Pillow-10.0.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib->-r requirements_short.txt (line 5)) (2.4.7)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas==1.5.3->-r requirements_short.txt (line 4)) (1.16.0)\n",
      "Downloading scikit_learn-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m301.7/301.7 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cycler-0.12.0-py3-none-any.whl (8.2 kB)\n",
      "Downloading fonttools-4.43.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m302.2/302.2 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading Pillow-10.0.1-cp310-cp310-manylinux_2_28_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2023.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m773.9/773.9 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.11.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m686.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm, threadpoolctl, scipy, regex, pillow, kiwisolver, joblib, fonttools, cycler, contourpy, scikit-learn, pandas, nltk, matplotlib\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.1.1\n",
      "    Uninstalling pandas-2.1.1:\n",
      "      Successfully uninstalled pandas-2.1.1\n",
      "Successfully installed contourpy-1.1.1 cycler-0.12.0 fonttools-4.43.0 joblib-1.3.2 kiwisolver-1.4.5 matplotlib-3.8.0 nltk-3.8.1 pandas-1.5.3 pillow-10.0.1 regex-2023.10.3 scikit-learn-1.3.1 scipy-1.11.3 threadpoolctl-3.2.0 tqdm-4.66.1\n"
     ]
    }
   ],
   "source": [
    "# pip install pandas\n",
    "\n",
    "# pip install scikit-learn\n",
    "\n",
    "!pip install -r requirements_short.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb6fd13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import pyreadr #package to allow us to read in .rds data files (native R datafile)\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "from collections import defaultdict\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import random\n",
    "from math import lgamma\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3188f16",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d322012f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file\n",
    "\n",
    "with open('french_election_broad(1).pkl', 'rb') as file:\n",
    "    # Load the object from the pickle file\n",
    "    df = pickle.load(file)\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87207361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>weight</th>\n",
       "      <th>text</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mehetia1</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>@demontvalon1 @EmmanuelMacron EtudiantsÂ : La #...</td>\n",
       "      <td>December</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LORZMichael_Off</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>Une honte. Hidalgo devrait Ãªtre virÃ© au plus v...</td>\n",
       "      <td>December</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thomas_France75</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>Ne plus fermer les yeux #presidentielles2022ğŸ‡«ğŸ‡·ğŸ‘‡ğŸ¼</td>\n",
       "      <td>December</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fmercier2017</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>Le nuclÃ©aire est certes productif, mais trop p...</td>\n",
       "      <td>December</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BerbreReineKah1</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>Que c'est beau de rÃªverğŸ˜¢\\nElle est belle la st...</td>\n",
       "      <td>December</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            source target  weight  \\\n",
       "0         Mehetia1   None       1   \n",
       "1  LORZMichael_Off   None       1   \n",
       "2  Thomas_France75   None       1   \n",
       "3     Fmercier2017   None       1   \n",
       "4  BerbreReineKah1   None       1   \n",
       "\n",
       "                                                text     month  \n",
       "0  @demontvalon1 @EmmanuelMacron EtudiantsÂ : La #...  December  \n",
       "1  Une honte. Hidalgo devrait Ãªtre virÃ© au plus v...  December  \n",
       "2   Ne plus fermer les yeux #presidentielles2022ğŸ‡«ğŸ‡·ğŸ‘‡ğŸ¼  December  \n",
       "3  Le nuclÃ©aire est certes productif, mais trop p...  December  \n",
       "4  Que c'est beau de rÃªverğŸ˜¢\\nElle est belle la st...  December  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b0c1ebb",
   "metadata": {},
   "source": [
    "## Cleaning columns and also the text of tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d574ce62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['text'].str.startswith(('rt', 'RT'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a64a9f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1262531"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b77fea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1dd10456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1262531"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4550e9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2130/4161460516.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text_original'] = df['text']\n",
      "/tmp/ipykernel_2130/4161460516.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] = df['text'].str.lower()\n"
     ]
    }
   ],
   "source": [
    "df['text_original'] = df['text']\n",
    "df['text'] = df['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "943c3975",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2130/854266914.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] = df['text'].str.replace(\"\\\\B@\\\\w+|^@\\\\w+\", \"\", regex = True)\n",
      "/tmp/ipykernel_2130/854266914.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] = df['text'].str.replace(\"&amp;\", \"and\")\n",
      "/tmp/ipykernel_2130/854266914.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] = df['text'].str.replace(\"(^RT|^via)((?:\\\\b\\\\W*@\\\\w+)+)\",\"\", regex=True, case=False)\n",
      "/tmp/ipykernel_2130/854266914.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] = df['text'].str.replace(\"(https|http)?:\\\\/\\\\/(\\\\w|\\\\.|\\\\/|\\\\?|\\\\=|\\\\&|\\\\%)*\\\\b\", \"\", regex = True)\n",
      "/tmp/ipykernel_2130/854266914.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] = df['text'].str.replace(\"[^ -~]\", \"\", regex = True)\n",
      "/tmp/ipykernel_2130/854266914.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] = df['text'].str.replace(\"\\\\s+\", \" \", regex = True)\n"
     ]
    }
   ],
   "source": [
    "# Remove mentions (posts that start with a \"@some_user_name \")\n",
    "df['text'] = df['text'].str.replace(\"\\\\B@\\\\w+|^@\\\\w+\", \"\", regex = True)\n",
    "# Change ampersands to \"and\"\n",
    "df['text'] = df['text'].str.replace(\"&amp;\", \"and\")\n",
    "# Remove the \"RT\" and \"via\" (old retweet style)\n",
    "df['text'] = df['text'].str.replace(\"(^RT|^via)((?:\\\\b\\\\W*@\\\\w+)+)\",\"\", regex=True, case=False)\n",
    "# Remove URLs             \n",
    "df['text'] = df['text'].str.replace(\"(https|http)?:\\\\/\\\\/(\\\\w|\\\\.|\\\\/|\\\\?|\\\\=|\\\\&|\\\\%)*\\\\b\", \"\", regex = True)\n",
    "# Keep ASCII only (removes Cyrillic, Japanese characters, etc.)\n",
    "df['text'] = df['text'].str.replace(\"[^ -~]\", \"\", regex = True)\n",
    "# Remove double+ spaces (e.g. \"build   the wall\" to \"build the wall\")\n",
    "df['text'] = df['text'].str.replace(\"\\\\s+\", \" \", regex = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c16b43",
   "metadata": {},
   "source": [
    "## Choosing reference words and seed words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebad1d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The keywords that add through the keyword discovery process\n",
    "\n",
    "reference_words_seed  = [\"presidentielle\",\"presidentielles\"] #first word we started with\n",
    "\n",
    "#reference_words_expanded = [\"covid-19\", \"coronavirus\"] #expanded list of keywords (just to show how it works)\n",
    "reference_words_expanded = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbb61902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The keywords that add through the keyword discovery process\n",
    "reference_words_excluded = [] #initial\n",
    "reference_words_excluded_expanded = [] #expanded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9f30e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the seed words and keywords added through discovery together\n",
    "\n",
    "reference_words = reference_words_seed + reference_words_expanded\n",
    "reference_words = \"|\".join(reference_words)\n",
    "\n",
    "reference_words_excluded = reference_words_excluded + reference_words_excluded_expanded\n",
    "reference_words_excluded = \"|\".join(reference_words_excluded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2feed4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'presidentielle|presidentielles'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97fdf8c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_words_excluded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b9eac12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# Will there be any keywords we want to exclude? this is simply a test \n",
    "excluded_words = len(reference_words_excluded.replace(\"|\", \"\")) > 0 #checks if there are more chars than 0, returns a bool\n",
    "\n",
    "print(excluded_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9966a60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2130/609187822.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['includes'] = df['text'].str.contains(pat = reference_words, regex = True, case = False)\n",
      "/tmp/ipykernel_2130/609187822.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['excludes'] = False\n"
     ]
    }
   ],
   "source": [
    "# Find tweets that contain any keywords that we want to include\n",
    "\n",
    "df['includes'] = df['text'].str.contains(pat = reference_words, regex = True, case = False)\n",
    "\n",
    "\n",
    "# Find tweets that contain any keywords that we want to exclude\n",
    "df['excludes'] = False\n",
    "if excluded_words:\n",
    "    df['excludes']  = df.loc[df['text'].str.contains(pat = reference_words_excluded, regex = True, case = False),:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60f5cb67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2130/1320542145.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['reference_set'] = (df['includes']== True) & (df['excludes'] == False) #all rows with the included and without the excluded\n",
      "/tmp/ipykernel_2130/1320542145.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['reference_set'] = df['reference_set'] *1 #make into numeric\n"
     ]
    }
   ],
   "source": [
    "# Just a bunch of TRUE and FALSE for the posts that include and exclude keywords\n",
    "df['reference_set'] = (df['includes']== True) & (df['excludes'] == False) #all rows with the included and without the excluded\n",
    "df['reference_set'] = df['reference_set'] *1 #make into numeric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac280f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    976332\n",
       "1    286199\n",
       "Name: reference_set, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how many of each?\n",
    "df['reference_set'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7971f94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2130/4067524263.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text_preprossed'] = df['text']\n",
      "/tmp/ipykernel_2130/4067524263.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text_preprossed'] = df['text'].str.replace(all_current_keywords, \"\", regex = True, case = False)\n"
     ]
    }
   ],
   "source": [
    "# We'll remove the keywords from the tweets so that the machine learning model\n",
    "# needs to use the words in each tweet that aren't those keywords to predict\n",
    "# whether it belongs in the target set or not the target set\n",
    "\n",
    "remove_keywords_from_tweets = True\n",
    "\n",
    "#make a reg-ex list of all the inclusion and exclusion words\n",
    "\n",
    "if excluded_words: #if there are exclusion words\n",
    "    all_current_keywords = reference_words + \"|\" + reference_words_excluded\n",
    "else:\n",
    "    all_current_keywords = reference_words\n",
    "\n",
    "\n",
    "df['text_preprossed'] = df['text']\n",
    "\n",
    "if remove_keywords_from_tweets:\n",
    "    df['text_preprossed'] = df['text'].str.replace(all_current_keywords, \"\", regex = True, case = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd828ecb",
   "metadata": {},
   "source": [
    "## Tokenisation of words in tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cfa51574",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = WhitespaceTokenizer()\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c8422774",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 327/1262531 [00:00<06:26, 3264.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1262531/1262531 [06:17<00:00, 3348.74it/s]\n"
     ]
    }
   ],
   "source": [
    "pre_prossed_sents =[]\n",
    "for sent in tqdm(df['text_preprossed']):\n",
    "    words = tokenizer.tokenize(sent)\n",
    "    words = [re.sub(r'\\d+', '', word) for word in words] #removing tokens that are only words \n",
    "    words = [x for x in words if x] #removing empty strings\n",
    "    sent_stem = [ps.stem(word) for word in words]\n",
    "    \n",
    "    sent_done = \" \".join(sent_stem)\n",
    "    pre_prossed_sents.append(sent_done)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d16e846d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2130/1358738971.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text_pre_stem'] = pre_prossed_sents\n"
     ]
    }
   ],
   "source": [
    "df['text_pre_stem'] = pre_prossed_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "776109a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1262531"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c0baa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[~df['text'].str.startswith(('rt', 'RT'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ef9c4461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1262441"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e07fa81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider saving a pkl at this time\n",
    "\n",
    "df.to_pickle('election_processed1.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cae9bb",
   "metadata": {},
   "source": [
    "## Stop words to remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5a52a7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ucloud/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words_french = list(set(stopwords.words('french')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23d4d9c",
   "metadata": {},
   "source": [
    "# Training model using reference set and sample of all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b8279a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  make a copy of DF for training only -- very small, only 10k \n",
    "\n",
    "df_train = df.copy()\n",
    "\n",
    "sample_size = 5000\n",
    "df_train = df.sample(n=sample_size, random_state=42)\n",
    "df_train.reset_index(inplace = True, drop = True)\n",
    "\n",
    "vectorizer = CountVectorizer(min_df = 10,\n",
    "                           max_df = 0.999,\n",
    "                           stop_words=stop_words_french,\n",
    "                          ngram_range = (1,2)) #set for larger n-grams\n",
    "\n",
    "corpus = vectorizer.fit_transform(df_train['text_pre_stem'])\n",
    "\n",
    "DTM_dict = {\"DTM\":corpus,\n",
    "               \"labels\":list(df_train['reference_set'])} \n",
    "\n",
    "# Determine how many tweets to sample for the training data\n",
    "\n",
    "# n_search = 3000\n",
    "n_search = min(sum(df_train['reference_set']==1)* 2, 50000)\n",
    "\n",
    "# Create lists of indices, indicating which belong to the reference set (those labelled to be about covid)\n",
    "#   and which do not belong to the reference set\n",
    "\n",
    "reference_ids = list(df_train[df_train['reference_set']==1].index)\n",
    "search_ids = list(df_train[df_train['reference_set']==0].index)\n",
    "\n",
    "# Taking a random sample of the search indices, i.e. those that do not belong to the reference set\n",
    "search_ids_sample = random.choices(search_ids, k=n_search)\n",
    "ids = reference_ids + search_ids_sample # putting them together to create the full list of training set indices\n",
    "\n",
    "# Checking amounts\n",
    "print(len(reference_ids),len(search_ids_sample),len(ids))\n",
    "\n",
    "# Saving the training data in a dict object\n",
    "DTM_train = {\"DTM\" : corpus[ids,:],\n",
    "            \"labels\": list(df_train['reference_set'][ids])}\n",
    "        \n",
    "# Defining the classifier\n",
    "\n",
    "#linear lasso\n",
    "#clf = linear_model.LassoCV(n_jobs=-1, verbose=1) #this was a mistake - should be log reg - small mistake though\n",
    "\n",
    "#logistic reg with lasso penalty - this will actually give probs e\n",
    "clf = linear_model.LogisticRegressionCV(penalty=\"l1\", n_jobs = -1, solver = \"saga\", max_iter=10000, verbose = 1)\n",
    "\n",
    "# Fitting the model. This takes some time. \n",
    "\n",
    "clf.fit(DTM_train['DTM'], DTM_train['labels']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "782d9fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.934652278177458\n",
      "Training Precision: 0.9496981891348089\n",
      "Training Recall: 0.8489208633093526\n",
      "Training F1 Score: 0.8964862298195632\n"
     ]
    }
   ],
   "source": [
    "# Testing performance now:\n",
    "\n",
    "# Making predictions on the training data\n",
    "train_predictions = clf.predict(DTM_train['DTM'])\n",
    "\n",
    "# Calculating evaluation metrics for the training set\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "accuracy_train = accuracy_score(DTM_train['labels'], train_predictions)\n",
    "precision_train = precision_score(DTM_train['labels'], train_predictions)\n",
    "recall_train = recall_score(DTM_train['labels'], train_predictions)\n",
    "f1_train = f1_score(DTM_train['labels'], train_predictions)\n",
    "\n",
    "print(\"Training Accuracy:\", accuracy_train)\n",
    "print(\"Training Precision:\", precision_train)\n",
    "print(\"Training Recall:\", recall_train)\n",
    "print(\"Training F1 Score:\", f1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2323386a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  now, scaling up to the whole df \n",
    "corpus2 = vectorizer.transform(df['text_pre_stem'])\n",
    "\n",
    "# Making predictions on the full dataset\n",
    "predictions = clf.predict(corpus2)\n",
    "\n",
    "# Check if all predictions are the same (we don't want this to be zero)\n",
    "# If so, there is a problem: potentially too few observations in the reference\n",
    "# set relative to the search set\n",
    "\n",
    "np.std(predictions)\n",
    "\n",
    "# Set a threshold\n",
    "\n",
    "threshold = 0.25\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fc42e07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving variables so far in a dict\n",
    "\n",
    "DTM_full = {'DTM':corpus2,\n",
    "            'raw_preds': predictions,\n",
    "            'preds': (predictions > threshold) * 1 ,\n",
    "            'reference': list(df['reference_set']==1),\n",
    "            'reference_ids': reference_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bc21e5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict whether each tweet is in the reference set based on a predicted\n",
    "# probability, where Pr(reference_set = 1) > threshold. Keep this low if want\n",
    "# more tweets to get into the target set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6fe740f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_var = []\n",
    "\n",
    "for i in range(0,len(DTM_full['preds'])):\n",
    "    if i in reference_ids: #if the obs is in the reference group\n",
    "        set_var.append('Reference')\n",
    "    \n",
    "    elif DTM_full['preds'][i] == 1:\n",
    "        set_var.append('Target')\n",
    "    \n",
    "    elif DTM_full['preds'][i] == 0:\n",
    "        set_var.append('Not target')\n",
    "    \n",
    "    else:\n",
    "        set_var.append(None)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "53a7c751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new dataframe of predictions \n",
    "\n",
    "pred_df = pd.DataFrame([pd.Series(DTM_full['preds']),pd.Series(set_var)]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "28bbc5f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>1</th>\n",
       "      <th>Not target</th>\n",
       "      <th>Reference</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>897018</td>\n",
       "      <td>882</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>230</td>\n",
       "      <td>364401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "1  Not target  Reference  Target\n",
       "0                               \n",
       "0      897018        882       0\n",
       "1           0        230  364401"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking performance (only classification of the reference observations are relevant to check)\n",
    "\n",
    "pd.crosstab(pred_df[0],pred_df[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "01669565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the Reference/Target/Not target in the dict \n",
    "\n",
    "DTM_full['set_var'] = set_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "158bef3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating 3 sets of indices\n",
    "\n",
    "target_ids = list(pd.Series(DTM_full['set_var']) == 'Target')\n",
    "not_target_ids = list(pd.Series(DTM_full['set_var']) == 'Not target')\n",
    "ref_ids = list(pd.Series(DTM_full['set_var']) == 'Reference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "61811aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating statistics for the target, not_target and reference sets \n",
    "\n",
    "target_freq = np.sum(DTM_full['DTM'][target_ids,:],0) #how many times is each token used in the target documents\n",
    "target_num_docs = np.sum(DTM_full['DTM'][target_ids,:] > 0, axis = 0) #how many target documents does each token appear in\n",
    "target_num_docs_prop =  target_num_docs / sum(target_ids) #proportion of target docs with each token\n",
    "\n",
    "\n",
    "not_target_freq = np.sum(DTM_full['DTM'][not_target_ids,:],0) #how many times is each token used in the not_target documents\n",
    "not_target_num_docs = np.sum(DTM_full['DTM'][not_target_ids,:]> 0,axis = 0) #how many not_target documents does each token appear in\n",
    "not_target_num_docs_prop =  not_target_num_docs / sum(not_target_ids) #proportion of not_target docs with each token\n",
    "\n",
    "\n",
    "ref_freq = np.sum(DTM_full['DTM'][ref_ids,:],0) #how many times is each token used in the reference documents\n",
    "ref_num_docs = np.sum(DTM_full['DTM'][ref_ids,:] > 0, axis = 0) #how many reference documents does each token appear in\n",
    "ref_num_docs_prop =  ref_num_docs / sum(ref_ids) #proportion of reference docs with each token\n",
    "\n",
    "\n",
    "# Saving the above in a dict \n",
    "\n",
    "d = {'target_freq' :target_freq.tolist()[0],\n",
    "    'target_num_docs': target_num_docs.tolist()[0],\n",
    "    'target_num_docs_prop': target_num_docs_prop.tolist()[0],\n",
    "    'not_target_freq':not_target_freq.tolist()[0],\n",
    "    'not_target_num_docs': not_target_num_docs.tolist()[0],\n",
    "    'not_target_num_docs_prop': not_target_num_docs_prop.tolist()[0],\n",
    "    'ref_freq':ref_freq.tolist()[0],\n",
    "    'ref_num_docs': ref_num_docs.tolist()[0],\n",
    "    'ref_num_docs_prop': ref_num_docs_prop.tolist()[0]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a9c402f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe based on the dict and token names\n",
    "\n",
    "df_prop = pd.DataFrame(d, index=vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "22d4fe59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsetting observations that are target or not target at least once (probably all)\n",
    "df_prop = df_prop.loc[(df_prop['target_freq']> 0) | (df_prop['not_target_freq'] > 0), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ce15091a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a column that is True if the token has a higher or equal proportion in the target set than in the not_target set. \n",
    "df_prop['target_larger'] = df_prop['target_num_docs_prop'] >= df_prop['not_target_num_docs_prop']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a278d54a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_freq</th>\n",
       "      <th>target_num_docs</th>\n",
       "      <th>target_num_docs_prop</th>\n",
       "      <th>not_target_freq</th>\n",
       "      <th>not_target_num_docs</th>\n",
       "      <th>not_target_num_docs_prop</th>\n",
       "      <th>ref_freq</th>\n",
       "      <th>ref_num_docs</th>\n",
       "      <th>ref_num_docs_prop</th>\n",
       "      <th>target_larger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>abord</th>\n",
       "      <td>489</td>\n",
       "      <td>486</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>1280</td>\n",
       "      <td>1257</td>\n",
       "      <td>0.001401</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001799</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>absolu</th>\n",
       "      <td>936</td>\n",
       "      <td>933</td>\n",
       "      <td>0.002560</td>\n",
       "      <td>3401</td>\n",
       "      <td>3371</td>\n",
       "      <td>0.003758</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.006295</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abstent</th>\n",
       "      <td>3334</td>\n",
       "      <td>3198</td>\n",
       "      <td>0.008776</td>\n",
       "      <td>1642</td>\n",
       "      <td>1637</td>\n",
       "      <td>0.001825</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accord</th>\n",
       "      <td>3451</td>\n",
       "      <td>3318</td>\n",
       "      <td>0.009105</td>\n",
       "      <td>2456</td>\n",
       "      <td>2440</td>\n",
       "      <td>0.002720</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.005396</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accueil</th>\n",
       "      <td>764</td>\n",
       "      <td>727</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>2448</td>\n",
       "      <td>2439</td>\n",
       "      <td>0.002719</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001799</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zemmourvillepint zemmourpresid</th>\n",
       "      <td>141</td>\n",
       "      <td>141</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>2365</td>\n",
       "      <td>2365</td>\n",
       "      <td>0.002637</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.007194</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zemmourvspecress</th>\n",
       "      <td>378</td>\n",
       "      <td>378</td>\n",
       "      <td>0.001037</td>\n",
       "      <td>3452</td>\n",
       "      <td>3451</td>\n",
       "      <td>0.003847</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zozz</th>\n",
       "      <td>344</td>\n",
       "      <td>341</td>\n",
       "      <td>0.000936</td>\n",
       "      <td>4291</td>\n",
       "      <td>4256</td>\n",
       "      <td>0.004745</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001799</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzz</th>\n",
       "      <td>494</td>\n",
       "      <td>489</td>\n",
       "      <td>0.001342</td>\n",
       "      <td>9876</td>\n",
       "      <td>9842</td>\n",
       "      <td>0.010972</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.006295</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzz montrez</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3765</td>\n",
       "      <td>3765</td>\n",
       "      <td>0.004197</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.003597</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1301 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                target_freq  target_num_docs  \\\n",
       "abord                                   489              486   \n",
       "absolu                                  936              933   \n",
       "abstent                                3334             3198   \n",
       "accord                                 3451             3318   \n",
       "accueil                                 764              727   \n",
       "...                                     ...              ...   \n",
       "zemmourvillepint zemmourpresid          141              141   \n",
       "zemmourvspecress                        378              378   \n",
       "zozz                                    344              341   \n",
       "zzz                                     494              489   \n",
       "zzz montrez                               0                0   \n",
       "\n",
       "                                target_num_docs_prop  not_target_freq  \\\n",
       "abord                                       0.001334             1280   \n",
       "absolu                                      0.002560             3401   \n",
       "abstent                                     0.008776             1642   \n",
       "accord                                      0.009105             2456   \n",
       "accueil                                     0.001995             2448   \n",
       "...                                              ...              ...   \n",
       "zemmourvillepint zemmourpresid              0.000387             2365   \n",
       "zemmourvspecress                            0.001037             3452   \n",
       "zozz                                        0.000936             4291   \n",
       "zzz                                         0.001342             9876   \n",
       "zzz montrez                                 0.000000             3765   \n",
       "\n",
       "                                not_target_num_docs  not_target_num_docs_prop  \\\n",
       "abord                                          1257                  0.001401   \n",
       "absolu                                         3371                  0.003758   \n",
       "abstent                                        1637                  0.001825   \n",
       "accord                                         2440                  0.002720   \n",
       "accueil                                        2439                  0.002719   \n",
       "...                                             ...                       ...   \n",
       "zemmourvillepint zemmourpresid                 2365                  0.002637   \n",
       "zemmourvspecress                               3451                  0.003847   \n",
       "zozz                                           4256                  0.004745   \n",
       "zzz                                            9842                  0.010972   \n",
       "zzz montrez                                    3765                  0.004197   \n",
       "\n",
       "                                ref_freq  ref_num_docs  ref_num_docs_prop  \\\n",
       "abord                                  2             2           0.001799   \n",
       "absolu                                 7             7           0.006295   \n",
       "abstent                                0             0           0.000000   \n",
       "accord                                 6             6           0.005396   \n",
       "accueil                                2             2           0.001799   \n",
       "...                                  ...           ...                ...   \n",
       "zemmourvillepint zemmourpresid         8             8           0.007194   \n",
       "zemmourvspecress                       0             0           0.000000   \n",
       "zozz                                   2             2           0.001799   \n",
       "zzz                                    7             7           0.006295   \n",
       "zzz montrez                            4             4           0.003597   \n",
       "\n",
       "                                target_larger  \n",
       "abord                                   False  \n",
       "absolu                                  False  \n",
       "abstent                                  True  \n",
       "accord                                   True  \n",
       "accueil                                 False  \n",
       "...                                       ...  \n",
       "zemmourvillepint zemmourpresid          False  \n",
       "zemmourvspecress                        False  \n",
       "zozz                                    False  \n",
       "zzz                                     False  \n",
       "zzz montrez                             False  \n",
       "\n",
       "[1301 rows x 10 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking a look at our new dataframe\n",
    "df_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c005dcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Likelihood function\n",
    "\n",
    "def llik(target_num_docs, nottarget_num_docs, target_num_docs_total, nottarget_num_docs_total):\n",
    "    '''No docstring - you neew to see what it does :) '''\n",
    "    x1 = ((lgamma(target_num_docs + 1) + lgamma(nottarget_num_docs + 1)) -\n",
    "           lgamma(target_num_docs + nottarget_num_docs + 1 + 1))\n",
    "    x2 = ((lgamma(target_num_docs_total - target_num_docs + 1) +\n",
    "           lgamma(nottarget_num_docs_total - nottarget_num_docs + 1)) -\n",
    "           lgamma(target_num_docs_total - target_num_docs +\n",
    "          nottarget_num_docs_total - nottarget_num_docs + 1 + 1))\n",
    "    llik = x1 + x2\n",
    "    return llik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ec1ff6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the total number of documents in the target and not_target sets \n",
    "\n",
    "target_num_docs_total = sum(target_ids)\n",
    "nottarget_num_docs_total =  sum(not_target_ids) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a6413a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the likelihood for each token\n",
    "\n",
    "llik_list= []\n",
    "for i in range(len(df_prop)):\n",
    "    t =df_prop['target_num_docs'][i]\n",
    "    nt =df_prop['not_target_num_docs'][i]\n",
    "    l = llik(t,nt,target_num_docs_total,nottarget_num_docs_total)\n",
    "    llik_list.append(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0ed061e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the likelihood scores \n",
    "\n",
    "df_prop['llik'] = llik_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4d8bdad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prop.to_pickle('output1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2fe6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # # # #  GOOD WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "6ff89e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_freq</th>\n",
       "      <th>target_num_docs</th>\n",
       "      <th>target_num_docs_prop</th>\n",
       "      <th>not_target_freq</th>\n",
       "      <th>not_target_num_docs</th>\n",
       "      <th>not_target_num_docs_prop</th>\n",
       "      <th>ref_freq</th>\n",
       "      <th>ref_num_docs</th>\n",
       "      <th>ref_num_docs_prop</th>\n",
       "      <th>target_larger</th>\n",
       "      <th>llik</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>macron macron</th>\n",
       "      <td>7666</td>\n",
       "      <td>7424</td>\n",
       "      <td>0.020373</td>\n",
       "      <td>5909</td>\n",
       "      <td>5645</td>\n",
       "      <td>0.006293</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.008993</td>\n",
       "      <td>True</td>\n",
       "      <td>-756078.348442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vote</th>\n",
       "      <td>25236</td>\n",
       "      <td>22598</td>\n",
       "      <td>0.062014</td>\n",
       "      <td>34597</td>\n",
       "      <td>31381</td>\n",
       "      <td>0.034984</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>0.022482</td>\n",
       "      <td>True</td>\n",
       "      <td>-756150.177194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>retrait</th>\n",
       "      <td>8173</td>\n",
       "      <td>7100</td>\n",
       "      <td>0.019484</td>\n",
       "      <td>5834</td>\n",
       "      <td>5388</td>\n",
       "      <td>0.006007</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000899</td>\n",
       "      <td>True</td>\n",
       "      <td>-756171.475699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rsultat</th>\n",
       "      <td>6635</td>\n",
       "      <td>6399</td>\n",
       "      <td>0.017560</td>\n",
       "      <td>4609</td>\n",
       "      <td>4524</td>\n",
       "      <td>0.005043</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.007194</td>\n",
       "      <td>True</td>\n",
       "      <td>-756210.944979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dmocrati</th>\n",
       "      <td>5414</td>\n",
       "      <td>5227</td>\n",
       "      <td>0.014344</td>\n",
       "      <td>3084</td>\n",
       "      <td>3054</td>\n",
       "      <td>0.003405</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.003597</td>\n",
       "      <td>True</td>\n",
       "      <td>-756214.134051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prsident rpubliqu</th>\n",
       "      <td>3352</td>\n",
       "      <td>3339</td>\n",
       "      <td>0.009163</td>\n",
       "      <td>1073</td>\n",
       "      <td>1071</td>\n",
       "      <td>0.001194</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>-756234.949911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>profit</th>\n",
       "      <td>2902</td>\n",
       "      <td>2842</td>\n",
       "      <td>0.007799</td>\n",
       "      <td>656</td>\n",
       "      <td>655</td>\n",
       "      <td>0.000730</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000899</td>\n",
       "      <td>True</td>\n",
       "      <td>-756237.538374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question</th>\n",
       "      <td>7197</td>\n",
       "      <td>6910</td>\n",
       "      <td>0.018963</td>\n",
       "      <td>5406</td>\n",
       "      <td>5305</td>\n",
       "      <td>0.005914</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.006295</td>\n",
       "      <td>True</td>\n",
       "      <td>-756259.928909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>er</th>\n",
       "      <td>9005</td>\n",
       "      <td>8673</td>\n",
       "      <td>0.023801</td>\n",
       "      <td>8008</td>\n",
       "      <td>7864</td>\n",
       "      <td>0.008767</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>0.010791</td>\n",
       "      <td>True</td>\n",
       "      <td>-756272.799596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dernier</th>\n",
       "      <td>4999</td>\n",
       "      <td>4902</td>\n",
       "      <td>0.013452</td>\n",
       "      <td>2870</td>\n",
       "      <td>2847</td>\n",
       "      <td>0.003174</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004496</td>\n",
       "      <td>True</td>\n",
       "      <td>-756334.017423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gauch</th>\n",
       "      <td>9929</td>\n",
       "      <td>8948</td>\n",
       "      <td>0.024555</td>\n",
       "      <td>9109</td>\n",
       "      <td>8606</td>\n",
       "      <td>0.009594</td>\n",
       "      <td>27</td>\n",
       "      <td>25</td>\n",
       "      <td>0.022482</td>\n",
       "      <td>True</td>\n",
       "      <td>-756400.047606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prsident</th>\n",
       "      <td>22253</td>\n",
       "      <td>20918</td>\n",
       "      <td>0.057404</td>\n",
       "      <td>31050</td>\n",
       "      <td>29825</td>\n",
       "      <td>0.033249</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>0.048561</td>\n",
       "      <td>True</td>\n",
       "      <td>-756475.900469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hidalgo</th>\n",
       "      <td>6860</td>\n",
       "      <td>6329</td>\n",
       "      <td>0.017368</td>\n",
       "      <td>5380</td>\n",
       "      <td>4945</td>\n",
       "      <td>0.005513</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0.008094</td>\n",
       "      <td>True</td>\n",
       "      <td>-756476.313402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comprendr</th>\n",
       "      <td>2712</td>\n",
       "      <td>2688</td>\n",
       "      <td>0.007376</td>\n",
       "      <td>731</td>\n",
       "      <td>729</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.002698</td>\n",
       "      <td>True</td>\n",
       "      <td>-756489.027888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avoir</th>\n",
       "      <td>11706</td>\n",
       "      <td>11201</td>\n",
       "      <td>0.030738</td>\n",
       "      <td>12854</td>\n",
       "      <td>12528</td>\n",
       "      <td>0.013966</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>0.015288</td>\n",
       "      <td>True</td>\n",
       "      <td>-756504.118744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emetour</th>\n",
       "      <td>1869</td>\n",
       "      <td>1845</td>\n",
       "      <td>0.005063</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>-756549.244978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>notr pays</th>\n",
       "      <td>2980</td>\n",
       "      <td>2953</td>\n",
       "      <td>0.008104</td>\n",
       "      <td>1046</td>\n",
       "      <td>1045</td>\n",
       "      <td>0.001165</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001799</td>\n",
       "      <td>True</td>\n",
       "      <td>-756577.200974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jeu</th>\n",
       "      <td>2131</td>\n",
       "      <td>2066</td>\n",
       "      <td>0.005670</td>\n",
       "      <td>336</td>\n",
       "      <td>335</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001799</td>\n",
       "      <td>True</td>\n",
       "      <td>-756596.686291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elys</th>\n",
       "      <td>2685</td>\n",
       "      <td>2659</td>\n",
       "      <td>0.007297</td>\n",
       "      <td>799</td>\n",
       "      <td>798</td>\n",
       "      <td>0.000890</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001799</td>\n",
       "      <td>True</td>\n",
       "      <td>-756598.301045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>castex</th>\n",
       "      <td>2195</td>\n",
       "      <td>2146</td>\n",
       "      <td>0.005889</td>\n",
       "      <td>404</td>\n",
       "      <td>401</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>0.013489</td>\n",
       "      <td>True</td>\n",
       "      <td>-756613.341791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>barrag</th>\n",
       "      <td>3844</td>\n",
       "      <td>3617</td>\n",
       "      <td>0.009926</td>\n",
       "      <td>1812</td>\n",
       "      <td>1769</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001799</td>\n",
       "      <td>True</td>\n",
       "      <td>-756616.855031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eelv</th>\n",
       "      <td>3513</td>\n",
       "      <td>3435</td>\n",
       "      <td>0.009426</td>\n",
       "      <td>1592</td>\n",
       "      <td>1573</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.003597</td>\n",
       "      <td>True</td>\n",
       "      <td>-756617.177426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expliqu</th>\n",
       "      <td>3281</td>\n",
       "      <td>3248</td>\n",
       "      <td>0.008913</td>\n",
       "      <td>1389</td>\n",
       "      <td>1387</td>\n",
       "      <td>0.001546</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.005396</td>\n",
       "      <td>True</td>\n",
       "      <td>-756625.074818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>noustou</th>\n",
       "      <td>4167</td>\n",
       "      <td>4162</td>\n",
       "      <td>0.011421</td>\n",
       "      <td>2405</td>\n",
       "      <td>2405</td>\n",
       "      <td>0.002681</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>-756625.882501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ds</th>\n",
       "      <td>7939</td>\n",
       "      <td>7634</td>\n",
       "      <td>0.020949</td>\n",
       "      <td>7360</td>\n",
       "      <td>7202</td>\n",
       "      <td>0.008029</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0.006295</td>\n",
       "      <td>True</td>\n",
       "      <td>-756630.868714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   target_freq  target_num_docs  target_num_docs_prop  \\\n",
       "macron macron             7666             7424              0.020373   \n",
       "vote                     25236            22598              0.062014   \n",
       "retrait                   8173             7100              0.019484   \n",
       "rsultat                   6635             6399              0.017560   \n",
       "dmocrati                  5414             5227              0.014344   \n",
       "prsident rpubliqu         3352             3339              0.009163   \n",
       "profit                    2902             2842              0.007799   \n",
       "question                  7197             6910              0.018963   \n",
       "er                        9005             8673              0.023801   \n",
       "dernier                   4999             4902              0.013452   \n",
       "gauch                     9929             8948              0.024555   \n",
       "prsident                 22253            20918              0.057404   \n",
       "hidalgo                   6860             6329              0.017368   \n",
       "comprendr                 2712             2688              0.007376   \n",
       "avoir                    11706            11201              0.030738   \n",
       "emetour                   1869             1845              0.005063   \n",
       "notr pays                 2980             2953              0.008104   \n",
       "jeu                       2131             2066              0.005670   \n",
       "elys                      2685             2659              0.007297   \n",
       "castex                    2195             2146              0.005889   \n",
       "barrag                    3844             3617              0.009926   \n",
       "eelv                      3513             3435              0.009426   \n",
       "expliqu                   3281             3248              0.008913   \n",
       "noustou                   4167             4162              0.011421   \n",
       "ds                        7939             7634              0.020949   \n",
       "\n",
       "                   not_target_freq  not_target_num_docs  \\\n",
       "macron macron                 5909                 5645   \n",
       "vote                         34597                31381   \n",
       "retrait                       5834                 5388   \n",
       "rsultat                       4609                 4524   \n",
       "dmocrati                      3084                 3054   \n",
       "prsident rpubliqu             1073                 1071   \n",
       "profit                         656                  655   \n",
       "question                      5406                 5305   \n",
       "er                            8008                 7864   \n",
       "dernier                       2870                 2847   \n",
       "gauch                         9109                 8606   \n",
       "prsident                     31050                29825   \n",
       "hidalgo                       5380                 4945   \n",
       "comprendr                      731                  729   \n",
       "avoir                        12854                12528   \n",
       "emetour                        174                  174   \n",
       "notr pays                     1046                 1045   \n",
       "jeu                            336                  335   \n",
       "elys                           799                  798   \n",
       "castex                         404                  401   \n",
       "barrag                        1812                 1769   \n",
       "eelv                          1592                 1573   \n",
       "expliqu                       1389                 1387   \n",
       "noustou                       2405                 2405   \n",
       "ds                            7360                 7202   \n",
       "\n",
       "                   not_target_num_docs_prop  ref_freq  ref_num_docs  \\\n",
       "macron macron                      0.006293        10            10   \n",
       "vote                               0.034984        30            25   \n",
       "retrait                            0.006007         1             1   \n",
       "rsultat                            0.005043         8             8   \n",
       "dmocrati                           0.003405         4             4   \n",
       "prsident rpubliqu                  0.001194         0             0   \n",
       "profit                             0.000730         1             1   \n",
       "question                           0.005914         7             7   \n",
       "er                                 0.008767        13            12   \n",
       "dernier                            0.003174         5             5   \n",
       "gauch                              0.009594        27            25   \n",
       "prsident                           0.033249        54            54   \n",
       "hidalgo                            0.005513        11             9   \n",
       "comprendr                          0.000813         3             3   \n",
       "avoir                              0.013966        18            17   \n",
       "emetour                            0.000194         0             0   \n",
       "notr pays                          0.001165         2             2   \n",
       "jeu                                0.000373         2             2   \n",
       "elys                               0.000890         2             2   \n",
       "castex                             0.000447        15            15   \n",
       "barrag                             0.001972         3             2   \n",
       "eelv                               0.001754         4             4   \n",
       "expliqu                            0.001546         6             6   \n",
       "noustou                            0.002681         0             0   \n",
       "ds                                 0.008029         8             7   \n",
       "\n",
       "                   ref_num_docs_prop  target_larger           llik  \n",
       "macron macron               0.008993           True -756078.348442  \n",
       "vote                        0.022482           True -756150.177194  \n",
       "retrait                     0.000899           True -756171.475699  \n",
       "rsultat                     0.007194           True -756210.944979  \n",
       "dmocrati                    0.003597           True -756214.134051  \n",
       "prsident rpubliqu           0.000000           True -756234.949911  \n",
       "profit                      0.000899           True -756237.538374  \n",
       "question                    0.006295           True -756259.928909  \n",
       "er                          0.010791           True -756272.799596  \n",
       "dernier                     0.004496           True -756334.017423  \n",
       "gauch                       0.022482           True -756400.047606  \n",
       "prsident                    0.048561           True -756475.900469  \n",
       "hidalgo                     0.008094           True -756476.313402  \n",
       "comprendr                   0.002698           True -756489.027888  \n",
       "avoir                       0.015288           True -756504.118744  \n",
       "emetour                     0.000000           True -756549.244978  \n",
       "notr pays                   0.001799           True -756577.200974  \n",
       "jeu                         0.001799           True -756596.686291  \n",
       "elys                        0.001799           True -756598.301045  \n",
       "castex                      0.013489           True -756613.341791  \n",
       "barrag                      0.001799           True -756616.855031  \n",
       "eelv                        0.003597           True -756617.177426  \n",
       "expliqu                     0.005396           True -756625.074818  \n",
       "noustou                     0.000000           True -756625.882501  \n",
       "ds                          0.006295           True -756630.868714  "
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prop.loc[df_prop['target_larger'] == True].sort_values('llik',ascending = False)[50:75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "13acf459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#Zemmour2emeTour\\n#JeNeSuisPasDextremeDroite #PourLesFranÃ§aisOubliÃ©s #JeVoteZemmour',\n",
       " \"@CharlotteGounot @EmmanuelMacron @BrunoLeMaire La vie est si belle qu'on risque la mort Ã  chaque coin de trottoir ! #JeVoteZemmour #Zemmour #Zemmour2emeTour #MacronDegage\",\n",
       " \"@BFMTV Tout Ã  fait d'accord ğŸ‘ğŸ»\\n\\nZEMMOUR PRÃ‰SIDENT â¤ï¸\\n\\n#Zemmour2emeTour \\n#JeVoteZemmour\",\n",
       " 'Je vote samedi en Guyane : je vote Zemmour #votezemmour #Zemmour #ZemmourPresident2022 #ZemmourProgramme #Zemmour2emeTour #Zemmour2022',\n",
       " '@lesRepublicains Pour DÃ‰GAGER MACRON  : #ZemmourMobilisationGenerale #ZemmourPresident2022 #Zemmour2emeTour',\n",
       " \"Petit travail artistique du jour. J'Ã©tais inspirÃ©e ğŸ˜\\n\\nLES ARTISTES AUSSI PEUVENT ÃŠTRE POUR ZEMMOUR ğŸ’– GZ ğŸ’–\\n\\n#JeVoteZemmour #JeVotePourZemmour #ZemmourMobilisationGenerale #ZemmourPresident2022 #LesFemmesAvecZemmour #Zemmour2022 #Zemmour2emeTour #ZemmourLeVoteVital #ZemmourEric https://t.co/rKGiZl2RSK\",\n",
       " '@kalyne2403 Aucun souci #ZemmourPresident2022 #Zemmour2022 #Zemmour2emeTour',\n",
       " '@GenerationZ_off @margauxtaillef2 @stanislasrig #EtSurtoutSURTOUTViveLaFrance ğŸ™ğŸŒ¿ğŸ™Œ\\n#ZemmourPresident #ZemmourReconquete #ZemmourTrocadero #Zemmour2022 #Zemmour2emeTour #Zemmour #ZemmourVaGagner\\n#Reconquete #ZemmourLeVoteVital #ZemmourPourTous #Zemmouriens #Zemmoureuse',\n",
       " '@ACCoudray et @GillesBouleau reÃ§oivent #Zemmour et sont repartis sur la polÃ©mique des prÃ©noms,candidat suivant @yjadot ,sourire et aucune polÃ©mique pour l\\'extrÃªme gauche notamment sur le triste \"juif de service\" lancÃ© par ce type Ã  l\\'encontre de #Zemmour2emeTour  \\n#JeVoteZemmour',\n",
       " '@CharlesMonsac ğŸ˜‚ğŸ˜‚ğŸ˜‚ Vous me semblez trÃ¨s en verve ce soir, @CharlesMonsac ! Je ne peux quâ€™acquiescerâ€¦ #JeVoteZemmour #ZemmourMobilisationGenerale #Zemmour2emeTour #ZemmourPresident',\n",
       " 'Vive le Â«\\xa0Z\\xa0Â» ğŸ”µâšªï¸ğŸ”´\\n#PourQueLaFranceResteLaFrance \\n#ZemmourPresident2022 \\n#Zemmour2emeTour',\n",
       " '@D_M_77 @vpecresse Valoche est finie ! Rejoignez tous en masse #ZemmourMobilisationGenerale #Zemmour #ZemmourPresident2022 #Zemmour2emeTour #ZemmourReconquete',\n",
       " '@JFB_jaimeZ0ZZ @PatriciaElodieB On va gagner, il reste 6 jours pour convaincre ! Encore et encore ! ğŸ‡«ğŸ‡·ğŸ’ª#ZemmourPresident #ZemmourTrocadero #Zemmour2emeTour #JeVotePourZemmour #JeVote #Zemmour',\n",
       " '@jjdenoual Ben voyons ! Apparemment, vous ne savez pas bien lire !#ZemmourMobilisationGenerale #Zemmour #ZemmourPresident2022 #ZemmourReconquete #Zemmour2emeTour',\n",
       " '#JeVoteZemmour #JeVoteEricZemmour #Zemmour2emeTour',\n",
       " '#MÃ©lenchon un faux insoumis en fait totalement #soumis...\\n#LFI le poids des mots...mais le choc de la rÃ©alitÃ© ğŸ˜·ğŸ¤\\n\\n#ReconquÃªte2022\\n#ZemmourPrÃ©sident\\n#Zemmour2emeTour \\n#PourQueLaFranceResteLaFrance \\n#VoteCache \\n#CireurDePompes\\n#GÃ©nerationZ https://t.co/f4hon6KWH1',\n",
       " '#MÃ©lenchon un faux insoumis en fait totalement #soumis...\\n#LFI le poids des mots...mais la dÃ©ception et le choc de la rÃ©alitÃ© ğŸ˜·ğŸ¤\\nDoux comme un agneau face Ã  Macron ğŸ˜‚\\n\\n#ReconquÃªte2022\\n#ZemmourPrÃ©sident\\n#Zemmour2emeTour \\n#PourQueLaFranceResteLaFrance \\n#VoteCache \\n#CireurDePompes https://t.co/oBKyNDSS9J',\n",
       " \"Bonne journÃ©e les amis ! ğŸ‡¨ğŸ‡µ N'oubliez pas la doudoune ce matin ğŸ¥¶\\n\\n#ZemmourPresident\\n#reconquete2022 #ZemmourLeVoteVital #Zemmour2emeTour #LesFemmesAvecZemmour #ViveLaFrance\\n\\n#PecresseNaufrage â¬‡ï¸\\nhttps://t.co/kHQxNpiCNy\",\n",
       " \"HÃ¢te d'Ãªtre Dimanche 20h ğŸ‡«ğŸ‡·\\n#JeVoteZemmour #ZemmourPresident \\n#Zemmour2emeTour\",\n",
       " '@CCastaner @EmmanuelMacron @_MaximeDavid @guillaumekasba @VigierPhilippe @LamiraultLuc @AnnaStpnoff @HHuwart @avecvous @enmarchefr Vous arrivez Ã  avoir des chaises vides ğŸ˜‚ğŸ˜‚ğŸ˜‚ mais putain que vous Ãªtes nul 6 jours et adieux le 2 eme tour \\n#MacronAdieuLe2emeTour']"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(see_in_context(\"emetour\").iloc[20:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ef096d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # # # # # #  BELOW IS NOT GOOD WORDS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "1a73a083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_freq</th>\n",
       "      <th>target_num_docs</th>\n",
       "      <th>target_num_docs_prop</th>\n",
       "      <th>not_target_freq</th>\n",
       "      <th>not_target_num_docs</th>\n",
       "      <th>not_target_num_docs_prop</th>\n",
       "      <th>ref_freq</th>\n",
       "      <th>ref_num_docs</th>\n",
       "      <th>ref_num_docs_prop</th>\n",
       "      <th>target_larger</th>\n",
       "      <th>llik</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>zemmourpresid</th>\n",
       "      <td>14301</td>\n",
       "      <td>14216</td>\n",
       "      <td>0.039012</td>\n",
       "      <td>242220</td>\n",
       "      <td>236202</td>\n",
       "      <td>0.263319</td>\n",
       "      <td>345</td>\n",
       "      <td>345</td>\n",
       "      <td>0.310252</td>\n",
       "      <td>False</td>\n",
       "      <td>-706871.414781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zemmourprsid</th>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>20007</td>\n",
       "      <td>19771</td>\n",
       "      <td>0.022041</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>0.019784</td>\n",
       "      <td>False</td>\n",
       "      <td>-752010.608028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>melenchonvagagn</th>\n",
       "      <td>2090</td>\n",
       "      <td>2089</td>\n",
       "      <td>0.005733</td>\n",
       "      <td>31127</td>\n",
       "      <td>30885</td>\n",
       "      <td>0.034431</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>0.046763</td>\n",
       "      <td>False</td>\n",
       "      <td>-752864.046717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zemmour</th>\n",
       "      <td>32496</td>\n",
       "      <td>29873</td>\n",
       "      <td>0.081978</td>\n",
       "      <td>147914</td>\n",
       "      <td>132192</td>\n",
       "      <td>0.147368</td>\n",
       "      <td>231</td>\n",
       "      <td>190</td>\n",
       "      <td>0.170863</td>\n",
       "      <td>False</td>\n",
       "      <td>-752971.150628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forc zemmourpresid</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>9505</td>\n",
       "      <td>9505</td>\n",
       "      <td>0.010596</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.003597</td>\n",
       "      <td>False</td>\n",
       "      <td>-755074.951515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>montrez votr</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>9496</td>\n",
       "      <td>9496</td>\n",
       "      <td>0.010586</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.003597</td>\n",
       "      <td>False</td>\n",
       "      <td>-755084.870952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>votr forc</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>9471</td>\n",
       "      <td>9471</td>\n",
       "      <td>0.010558</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.003597</td>\n",
       "      <td>False</td>\n",
       "      <td>-755086.636738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>montrez</th>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>9648</td>\n",
       "      <td>9646</td>\n",
       "      <td>0.010753</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.003597</td>\n",
       "      <td>False</td>\n",
       "      <td>-755344.292778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zemmour zemmourpresid</th>\n",
       "      <td>1780</td>\n",
       "      <td>1773</td>\n",
       "      <td>0.004866</td>\n",
       "      <td>19527</td>\n",
       "      <td>19467</td>\n",
       "      <td>0.021702</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>0.027878</td>\n",
       "      <td>False</td>\n",
       "      <td>-755535.119801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lafrancedanslesyeux</th>\n",
       "      <td>431</td>\n",
       "      <td>431</td>\n",
       "      <td>0.001183</td>\n",
       "      <td>11771</td>\n",
       "      <td>11758</td>\n",
       "      <td>0.013108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>-755612.663393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facealaguerretf</th>\n",
       "      <td>567</td>\n",
       "      <td>567</td>\n",
       "      <td>0.001556</td>\n",
       "      <td>12010</td>\n",
       "      <td>11995</td>\n",
       "      <td>0.013372</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>-755810.065512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ric zemmour</th>\n",
       "      <td>6964</td>\n",
       "      <td>6951</td>\n",
       "      <td>0.019075</td>\n",
       "      <td>39528</td>\n",
       "      <td>39083</td>\n",
       "      <td>0.043570</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0.009892</td>\n",
       "      <td>False</td>\n",
       "      <td>-755813.809583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marinepresident</th>\n",
       "      <td>7591</td>\n",
       "      <td>7577</td>\n",
       "      <td>0.020793</td>\n",
       "      <td>39234</td>\n",
       "      <td>38743</td>\n",
       "      <td>0.043191</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>-756265.323542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzz</th>\n",
       "      <td>494</td>\n",
       "      <td>489</td>\n",
       "      <td>0.001342</td>\n",
       "      <td>9876</td>\n",
       "      <td>9842</td>\n",
       "      <td>0.010972</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.006295</td>\n",
       "      <td>False</td>\n",
       "      <td>-756305.279774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comm</th>\n",
       "      <td>10498</td>\n",
       "      <td>10154</td>\n",
       "      <td>0.027865</td>\n",
       "      <td>49184</td>\n",
       "      <td>46646</td>\n",
       "      <td>0.052001</td>\n",
       "      <td>58</td>\n",
       "      <td>52</td>\n",
       "      <td>0.046763</td>\n",
       "      <td>False</td>\n",
       "      <td>-756390.124969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zemmour lafrancedanslesyeux</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>6290</td>\n",
       "      <td>6290</td>\n",
       "      <td>0.007012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>-756390.898157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rt voix</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5571</td>\n",
       "      <td>5571</td>\n",
       "      <td>0.006211</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.003597</td>\n",
       "      <td>False</td>\n",
       "      <td>-756410.048573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jevotemelenchon</th>\n",
       "      <td>3900</td>\n",
       "      <td>3897</td>\n",
       "      <td>0.010694</td>\n",
       "      <td>24762</td>\n",
       "      <td>24451</td>\n",
       "      <td>0.027258</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>-756448.818717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zemmourpresid zemmour</th>\n",
       "      <td>655</td>\n",
       "      <td>655</td>\n",
       "      <td>0.001797</td>\n",
       "      <td>10280</td>\n",
       "      <td>10243</td>\n",
       "      <td>0.011419</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>0.035072</td>\n",
       "      <td>False</td>\n",
       "      <td>-756469.991300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forc</th>\n",
       "      <td>1854</td>\n",
       "      <td>1838</td>\n",
       "      <td>0.005044</td>\n",
       "      <td>15948</td>\n",
       "      <td>15799</td>\n",
       "      <td>0.017613</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0.010791</td>\n",
       "      <td>False</td>\n",
       "      <td>-756516.681535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             target_freq  target_num_docs  \\\n",
       "zemmourpresid                      14301            14216   \n",
       "zemmourprsid                          99               99   \n",
       "melenchonvagagn                     2090             2089   \n",
       "zemmour                            32496            29873   \n",
       "forc zemmourpresid                     2                2   \n",
       "montrez votr                           3                3   \n",
       "votr forc                              2                2   \n",
       "montrez                               72               72   \n",
       "zemmour zemmourpresid               1780             1773   \n",
       "lafrancedanslesyeux                  431              431   \n",
       "facealaguerretf                      567              567   \n",
       "ric zemmour                         6964             6951   \n",
       "marinepresident                     7591             7577   \n",
       "zzz                                  494              489   \n",
       "comm                               10498            10154   \n",
       "zemmour lafrancedanslesyeux           50               50   \n",
       "rt voix                                0                0   \n",
       "jevotemelenchon                     3900             3897   \n",
       "zemmourpresid zemmour                655              655   \n",
       "forc                                1854             1838   \n",
       "\n",
       "                             target_num_docs_prop  not_target_freq  \\\n",
       "zemmourpresid                            0.039012           242220   \n",
       "zemmourprsid                             0.000272            20007   \n",
       "melenchonvagagn                          0.005733            31127   \n",
       "zemmour                                  0.081978           147914   \n",
       "forc zemmourpresid                       0.000005             9505   \n",
       "montrez votr                             0.000008             9496   \n",
       "votr forc                                0.000005             9471   \n",
       "montrez                                  0.000198             9648   \n",
       "zemmour zemmourpresid                    0.004866            19527   \n",
       "lafrancedanslesyeux                      0.001183            11771   \n",
       "facealaguerretf                          0.001556            12010   \n",
       "ric zemmour                              0.019075            39528   \n",
       "marinepresident                          0.020793            39234   \n",
       "zzz                                      0.001342             9876   \n",
       "comm                                     0.027865            49184   \n",
       "zemmour lafrancedanslesyeux              0.000137             6290   \n",
       "rt voix                                  0.000000             5571   \n",
       "jevotemelenchon                          0.010694            24762   \n",
       "zemmourpresid zemmour                    0.001797            10280   \n",
       "forc                                     0.005044            15948   \n",
       "\n",
       "                             not_target_num_docs  not_target_num_docs_prop  \\\n",
       "zemmourpresid                             236202                  0.263319   \n",
       "zemmourprsid                               19771                  0.022041   \n",
       "melenchonvagagn                            30885                  0.034431   \n",
       "zemmour                                   132192                  0.147368   \n",
       "forc zemmourpresid                          9505                  0.010596   \n",
       "montrez votr                                9496                  0.010586   \n",
       "votr forc                                   9471                  0.010558   \n",
       "montrez                                     9646                  0.010753   \n",
       "zemmour zemmourpresid                      19467                  0.021702   \n",
       "lafrancedanslesyeux                        11758                  0.013108   \n",
       "facealaguerretf                            11995                  0.013372   \n",
       "ric zemmour                                39083                  0.043570   \n",
       "marinepresident                            38743                  0.043191   \n",
       "zzz                                         9842                  0.010972   \n",
       "comm                                       46646                  0.052001   \n",
       "zemmour lafrancedanslesyeux                 6290                  0.007012   \n",
       "rt voix                                     5571                  0.006211   \n",
       "jevotemelenchon                            24451                  0.027258   \n",
       "zemmourpresid zemmour                      10243                  0.011419   \n",
       "forc                                       15799                  0.017613   \n",
       "\n",
       "                             ref_freq  ref_num_docs  ref_num_docs_prop  \\\n",
       "zemmourpresid                     345           345           0.310252   \n",
       "zemmourprsid                       22            22           0.019784   \n",
       "melenchonvagagn                    52            52           0.046763   \n",
       "zemmour                           231           190           0.170863   \n",
       "forc zemmourpresid                  4             4           0.003597   \n",
       "montrez votr                        4             4           0.003597   \n",
       "votr forc                           4             4           0.003597   \n",
       "montrez                             4             4           0.003597   \n",
       "zemmour zemmourpresid              31            31           0.027878   \n",
       "lafrancedanslesyeux                 0             0           0.000000   \n",
       "facealaguerretf                     0             0           0.000000   \n",
       "ric zemmour                        11            11           0.009892   \n",
       "marinepresident                     0             0           0.000000   \n",
       "zzz                                 7             7           0.006295   \n",
       "comm                               58            52           0.046763   \n",
       "zemmour lafrancedanslesyeux         0             0           0.000000   \n",
       "rt voix                             4             4           0.003597   \n",
       "jevotemelenchon                     0             0           0.000000   \n",
       "zemmourpresid zemmour              39            39           0.035072   \n",
       "forc                               12            12           0.010791   \n",
       "\n",
       "                             target_larger           llik  \n",
       "zemmourpresid                        False -706871.414781  \n",
       "zemmourprsid                         False -752010.608028  \n",
       "melenchonvagagn                      False -752864.046717  \n",
       "zemmour                              False -752971.150628  \n",
       "forc zemmourpresid                   False -755074.951515  \n",
       "montrez votr                         False -755084.870952  \n",
       "votr forc                            False -755086.636738  \n",
       "montrez                              False -755344.292778  \n",
       "zemmour zemmourpresid                False -755535.119801  \n",
       "lafrancedanslesyeux                  False -755612.663393  \n",
       "facealaguerretf                      False -755810.065512  \n",
       "ric zemmour                          False -755813.809583  \n",
       "marinepresident                      False -756265.323542  \n",
       "zzz                                  False -756305.279774  \n",
       "comm                                 False -756390.124969  \n",
       "zemmour lafrancedanslesyeux          False -756390.898157  \n",
       "rt voix                              False -756410.048573  \n",
       "jevotemelenchon                      False -756448.818717  \n",
       "zemmourpresid zemmour                False -756469.991300  \n",
       "forc                                 False -756516.681535  "
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prop.loc[df_prop['target_larger'] == False].sort_values('llik',ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "adce70b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def see_in_context(term):\n",
    "    '''Gets the tweets orginial text with the term - also supports regex - seachers the full tect\n",
    "    only returns tweets not in the orginial reference list'''\n",
    "    if list(vectorizer.get_feature_names_out()):\n",
    "        subset = df.loc[(df['text_original'].str.contains(pat = term,regex = True, case = False)) & (df['reference_set'] == False),'text_original']\n",
    "        if len(subset) != 0:\n",
    "            return subset\n",
    "        else:\n",
    "            print(\"This is not a term in the corpus\")\n",
    "\n",
    "    else:\n",
    "        print(\"This is not a term in the corpus\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50891f87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "see_in_context(\"montrez votr\").iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a4023f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_elites = pd.read_excel('Elite actors list and keywords_2023.10.06.15.30.xlsx', sheet_name='all_mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4dd067eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Twitter</th>\n",
       "      <th>Position</th>\n",
       "      <th>Affilation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://twitter.com/PapNdiaye</td>\n",
       "      <td>Government</td>\n",
       "      <td>LFM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://twitter.com/sretailleau</td>\n",
       "      <td>Government</td>\n",
       "      <td>LFM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://twitter.com/RimaAbdulMalak</td>\n",
       "      <td>Government</td>\n",
       "      <td>LFM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://twitter.com/E_DupondM</td>\n",
       "      <td>Government</td>\n",
       "      <td>LFM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://twitter.com/MinColonna</td>\n",
       "      <td>Government</td>\n",
       "      <td>LFM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Twitter    Position Affilation\n",
       "0       https://twitter.com/PapNdiaye  Government        LFM\n",
       "1     https://twitter.com/sretailleau  Government        LFM\n",
       "2  https://twitter.com/RimaAbdulMalak  Government        LFM\n",
       "3       https://twitter.com/E_DupondM  Government        LFM\n",
       "4      https://twitter.com/MinColonna  Government        LFM"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_elites.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "568fe0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_elites['handles'] = df_elites['Twitter'].str.extract(r'https:\\/\\/twitter\\.com\\/(\\w+)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "6160916d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Twitter</th>\n",
       "      <th>Position</th>\n",
       "      <th>Affilation</th>\n",
       "      <th>handles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://twitter.com/PapNdiaye</td>\n",
       "      <td>Government</td>\n",
       "      <td>LFM</td>\n",
       "      <td>PapNdiaye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://twitter.com/sretailleau</td>\n",
       "      <td>Government</td>\n",
       "      <td>LFM</td>\n",
       "      <td>sretailleau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://twitter.com/RimaAbdulMalak</td>\n",
       "      <td>Government</td>\n",
       "      <td>LFM</td>\n",
       "      <td>RimaAbdulMalak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://twitter.com/E_DupondM</td>\n",
       "      <td>Government</td>\n",
       "      <td>LFM</td>\n",
       "      <td>E_DupondM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://twitter.com/MinColonna</td>\n",
       "      <td>Government</td>\n",
       "      <td>LFM</td>\n",
       "      <td>MinColonna</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Twitter    Position Affilation         handles\n",
       "0       https://twitter.com/PapNdiaye  Government        LFM       PapNdiaye\n",
       "1     https://twitter.com/sretailleau  Government        LFM     sretailleau\n",
       "2  https://twitter.com/RimaAbdulMalak  Government        LFM  RimaAbdulMalak\n",
       "3       https://twitter.com/E_DupondM  Government        LFM       E_DupondM\n",
       "4      https://twitter.com/MinColonna  Government        LFM      MinColonna"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_elites.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "9c9ba1c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "552"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_elites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1af1f419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Twitter', 'Position', 'Affilation', 'handles'], dtype='object')"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_elites.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "5441baa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>weight</th>\n",
       "      <th>text</th>\n",
       "      <th>month</th>\n",
       "      <th>text_original</th>\n",
       "      <th>includes</th>\n",
       "      <th>excludes</th>\n",
       "      <th>reference_set</th>\n",
       "      <th>text_preprossed</th>\n",
       "      <th>text_pre_stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mehetia1</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>etudiants: la #france devenue un pays du tier...</td>\n",
       "      <td>December</td>\n",
       "      <td>@demontvalon1 @EmmanuelMacron EtudiantsÂ : La #...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>etudiants: la #france devenue un pays du tier...</td>\n",
       "      <td>etudiants: la #franc devenu un pay du tiers-mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LORZMichael_Off</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>une honte. hidalgo devrait tre vir au plus vit...</td>\n",
       "      <td>December</td>\n",
       "      <td>Une honte. Hidalgo devrait Ãªtre virÃ© au plus v...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>une honte. hidalgo devrait tre vir au plus vit...</td>\n",
       "      <td>une honte. hidalgo devrait tre vir au plu vite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thomas_France75</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>ne plus fermer les yeux #presidentielles2022</td>\n",
       "      <td>December</td>\n",
       "      <td>Ne plus fermer les yeux #presidentielles2022ğŸ‡«ğŸ‡·ğŸ‘‡ğŸ¼</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>ne plus fermer les yeux #s2022</td>\n",
       "      <td>ne plu fermer le yeux #s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fmercier2017</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>le nuclaire est certes productif, mais trop pr...</td>\n",
       "      <td>December</td>\n",
       "      <td>Le nuclÃ©aire est certes productif, mais trop p...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>le nuclaire est certes productif, mais trop pr...</td>\n",
       "      <td>le nuclair est cert productif, mai trop problm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BerbreReineKah1</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>que c'est beau de rverelle est belle la start-...</td>\n",
       "      <td>December</td>\n",
       "      <td>Que c'est beau de rÃªverğŸ˜¢\\nElle est belle la st...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>que c'est beau de rverelle est belle la start-...</td>\n",
       "      <td>que c'est beau de rverel est bell la start-up ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            source target  weight  \\\n",
       "0         Mehetia1   None       1   \n",
       "1  LORZMichael_Off   None       1   \n",
       "2  Thomas_France75   None       1   \n",
       "3     Fmercier2017   None       1   \n",
       "4  BerbreReineKah1   None       1   \n",
       "\n",
       "                                                text     month  \\\n",
       "0   etudiants: la #france devenue un pays du tier...  December   \n",
       "1  une honte. hidalgo devrait tre vir au plus vit...  December   \n",
       "2       ne plus fermer les yeux #presidentielles2022  December   \n",
       "3  le nuclaire est certes productif, mais trop pr...  December   \n",
       "4  que c'est beau de rverelle est belle la start-...  December   \n",
       "\n",
       "                                       text_original  includes  excludes  \\\n",
       "0  @demontvalon1 @EmmanuelMacron EtudiantsÂ : La #...      True     False   \n",
       "1  Une honte. Hidalgo devrait Ãªtre virÃ© au plus v...     False     False   \n",
       "2   Ne plus fermer les yeux #presidentielles2022ğŸ‡«ğŸ‡·ğŸ‘‡ğŸ¼      True     False   \n",
       "3  Le nuclÃ©aire est certes productif, mais trop p...     False     False   \n",
       "4  Que c'est beau de rÃªverğŸ˜¢\\nElle est belle la st...     False     False   \n",
       "\n",
       "   reference_set                                    text_preprossed  \\\n",
       "0              1   etudiants: la #france devenue un pays du tier...   \n",
       "1              0  une honte. hidalgo devrait tre vir au plus vit...   \n",
       "2              1                     ne plus fermer les yeux #s2022   \n",
       "3              0  le nuclaire est certes productif, mais trop pr...   \n",
       "4              0  que c'est beau de rverelle est belle la start-...   \n",
       "\n",
       "                                       text_pre_stem  \n",
       "0  etudiants: la #franc devenu un pay du tiers-mo...  \n",
       "1  une honte. hidalgo devrait tre vir au plu vite...  \n",
       "2                           ne plu fermer le yeux #s  \n",
       "3  le nuclair est cert productif, mai trop problm...  \n",
       "4  que c'est beau de rverel est bell la start-up ...  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "2ac44507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              handle  sum Affilation                Position\n",
      "0          PapNdiaye    0        LFM              Government\n",
      "1        sretailleau    0        LFM              Government\n",
      "2     RimaAbdulMalak    0        LFM              Government\n",
      "3          E_DupondM    3        LFM              Government\n",
      "4         MinColonna    0        LFM              Government\n",
      "..               ...  ...        ...                     ...\n",
      "498             EELV  218       EELV        Official Account\n",
      "499           yjadot  837       EELV            Party Leader\n",
      "500  lesrepublicains    0         LR  Official Party Account\n",
      "501        vpecresse  519         LR            Party Leader\n",
      "502              NaN    0       None                    None\n",
      "\n",
      "[503 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df and df_elites are your DataFrames\n",
    "\n",
    "# Initialize an empty list to store the results\n",
    "elite_actors_tweet_nb = []\n",
    "\n",
    "# Loop through unique handles in df_elites\n",
    "for handle in df_elites['handles'].unique():\n",
    "    # Count the number of rows where 'source' matches the current handle\n",
    "    matching_rows = df[df['source'] == handle].shape[0]\n",
    "    \n",
    "    # Check if there are matching rows in df_elites for the current handle\n",
    "    if len(df_elites[df_elites['handles'] == handle]) > 0:\n",
    "        # Get the affiliation and position for the current handle\n",
    "        affiliation = df_elites.loc[df_elites['handles'] == handle, 'Affilation'].values[0]\n",
    "        position = df_elites.loc[df_elites['handles'] == handle, 'Position'].values[0]\n",
    "    else:\n",
    "        affiliation = None  # Set affiliation as None if there are no matching rows\n",
    "        position = None  # Set position as None if there are no matching rows\n",
    "    \n",
    "    # Append handle, sum, affiliation, and position to the results list\n",
    "    elite_actors_tweet_nb.append({'handle': handle, 'sum': matching_rows, 'Affilation': affiliation, 'Position': position})\n",
    "\n",
    "# Create a new DataFrame from the results list\n",
    "elite_actors_tweet_nb_df = pd.DataFrame(elite_actors_tweet_nb)\n",
    "\n",
    "# Print the new DataFrame\n",
    "print(elite_actors_tweet_nb_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "58c16742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>handle</th>\n",
       "      <th>sum</th>\n",
       "      <th>Affilation</th>\n",
       "      <th>Position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>yjadot</td>\n",
       "      <td>837</td>\n",
       "      <td>EELV</td>\n",
       "      <td>Party Leader</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>MLP_officiel</td>\n",
       "      <td>669</td>\n",
       "      <td>RN</td>\n",
       "      <td>Party Leader</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>vpecresse</td>\n",
       "      <td>519</td>\n",
       "      <td>LR</td>\n",
       "      <td>Party Leader</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>JulienOdoul</td>\n",
       "      <td>421</td>\n",
       "      <td>RN</td>\n",
       "      <td>MP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>ljacobelli</td>\n",
       "      <td>246</td>\n",
       "      <td>RN</td>\n",
       "      <td>MP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>MickaelNogal</td>\n",
       "      <td>0</td>\n",
       "      <td>LFM</td>\n",
       "      <td>MP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>LoicDombreval</td>\n",
       "      <td>0</td>\n",
       "      <td>LFM</td>\n",
       "      <td>MP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>MarieAngeMagne</td>\n",
       "      <td>0</td>\n",
       "      <td>LFM</td>\n",
       "      <td>MP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Fdumas2017</td>\n",
       "      <td>0</td>\n",
       "      <td>LFM</td>\n",
       "      <td>MP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>JocelynDessigny</td>\n",
       "      <td>0</td>\n",
       "      <td>RN</td>\n",
       "      <td>MP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>503 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              handle  sum Affilation      Position\n",
       "499           yjadot  837       EELV  Party Leader\n",
       "295     MLP_officiel  669         RN  Party Leader\n",
       "501        vpecresse  519         LR  Party Leader\n",
       "381      JulienOdoul  421         RN            MP\n",
       "357       ljacobelli  246         RN            MP\n",
       "..               ...  ...        ...           ...\n",
       "283     MickaelNogal    0        LFM            MP\n",
       "286    LoicDombreval    0        LFM            MP\n",
       "101   MarieAngeMagne    0        LFM            MP\n",
       "108       Fdumas2017    0        LFM            MP\n",
       "347  JocelynDessigny    0         RN            MP\n",
       "\n",
       "[503 rows x 4 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elite_actors_tweet_nb_df.sort_values(by='sum', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "83b8f0e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(elite_actors_tweet_nb_df[elite_actors_tweet_nb_df['sum'] == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "18e8eeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "elite_actors_tweet_nb_df.to_excel('elite_actors_tweet_nb_3.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
